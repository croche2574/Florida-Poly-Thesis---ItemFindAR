%% Use Article for journal papers, InProceedings for conference papers, TechReport for technical reports, Book for books, PhdThesis for Ph.D. theses.

@misc{LabelStudio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2022},
}

@misc{Roboflow,
  title={Roboflow (Version 1.0) [Software]},
  url={https://roboflow.com},
  note={Available from https://roboflow.com},
  author={
    Dwyer, B. and
    Nelson, J. and 
    Hansen, T. and
    et. al.},
  year={2024},
}

@misc{Jocher_Ultralytics_YOLO_2023,
author = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
license = {AGPL-3.0},
month = jan,
title = {{Ultralytics YOLO}},
url = {https://github.com/ultralytics/ultralytics},
version = {8.0.0},
year = {2023}
}

@incollection{brooke_sus_1996,
	title = {{SUS} -- a quick and dirty usability scale},
	author = {Brooke, John},
	month = jan,
	year = {1996},
	pages = {189--194},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\GE3N7T6N\\Brooke - 1996 - SUS -- a quick and dirty usability scale.pdf:application/pdf},
}

@article{smith_interprocess_2017,
	title = {Interprocess communication with {Java} in a {Microsoft} {Windows} {Environment}},
	volume = {29},
	issn = {2313-7835},
	url = {http://www.scielo.org.za/scielo.php?script=sci_abstract&pid=S2313-78352017000300010&lng=en&nrm=iso&tlng=en},
	doi = {10.18489/sacj.v29i3.500},
	number = {3},
	urldate = {2022-12-04},
	journal = {South African Computer Journal},
	author = {Smith, Dylan and Wells, George},
	year = {2017},
	note = {Publisher: South African Computer Journal},
	pages = {198--214},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\YPF3Y2GR\\Smith and Wells - 2017 - Interprocess communication with Java in a Microsof.pdf:application/pdf;Snapshot:C\:\\Users\\croch\\Zotero\\storage\\EKDFU37S\\scielo.html:text/html},
}

@article{keshav_how_2007,
	title = {How to read a paper},
	volume = {37},
	issn = {0146-4833},
	url = {https://doi.org/10.1145/1273445.1273458},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	number = {3},
	urldate = {2022-10-31},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Keshav, S.},
	month = jul,
	year = {2007},
	keywords = {hints, paper, reading},
	pages = {83--84},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\ZB5NK3RB\\Keshav - 2007 - How to read a paper.pdf:application/pdf},
}

@inproceedings{tu_understanding_2019,
	address = {Providence RI USA},
	title = {Understanding {Real}-{World} {Concurrency} {Bugs} in {Go}},
	isbn = {978-1-4503-6240-5},
	url = {https://dl.acm.org/doi/10.1145/3297858.3304069},
	doi = {10.1145/3297858.3304069},
	abstract = {Go is a statically-typed programming language that aims to provide a simple, efficient, and safe way to build multithreaded software. Since its creation in 2009, Go has matured and gained significant adoption in production and open-source software. Go advocates for the usage of message passing as the means of inter-thread communication and provides several new concurrency mechanisms and libraries to ease multi-threading programming. It is important to understand the implication of these new proposals and the comparison of message passing and shared memory synchronization in terms of program errors, or bugs. Unfortunately, as far as we know, there has been no study on Go’s concurrency bugs.},
	language = {en},
	urldate = {2022-10-31},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Tu, Tengfei and Liu, Xiaoyu and Song, Linhai and Zhang, Yiying},
	month = apr,
	year = {2019},
	pages = {865--878},
	file = {Tu et al. - 2019 - Understanding Real-World Concurrency Bugs in Go.pdf:C\:\\Users\\croch\\Zotero\\storage\\HERCYZGJ\\Tu et al. - 2019 - Understanding Real-World Concurrency Bugs in Go.pdf:application/pdf},
}

@article{keshav_how_2007-1,
	title = {How to read a paper},
	volume = {37},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However; this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-Pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	journal = {Computer Communication Review},
	author = {Keshav, Satish},
	month = jul,
	year = {2007},
	pages = {83--84},
}

@article{kleinow_clientserver_2002,
	title = {Client/{Server} based {Statistical} {Computing}},
	volume = {17},
	issn = {0943-4062},
	url = {https://doi.org/10.1007/s001800200109},
	doi = {10.1007/s001800200109},
	abstract = {We propose a client server architecture for statistical computing. The main feature of our approach is the possibility to connect various client programs via a TCP/IP connection to a powerful statistical engine. This offers the opportunity to include the statistical engine into a number of software packages and to empower the user of these packages to access a modern statistical programming environment. It also allows for the development of specialized client programs for particular tasks. TCP/IP permits a client/server connection with the client and server running on different hosts (remote host) as well as running both applications on the same computer (local host). To have a large flexibility we suggest adding a middleware program managing the communication between Server and Client. This avoids the need to implement TCP/IP communication methods on the server side. The paper provides an overview of the desired environment and illustrates the general structure by the implementation of the XploRe Quantlet Client and XploRe Quantlet Server.},
	number = {3},
	urldate = {2022-10-10},
	journal = {Comput. Stat.},
	author = {Kleinow, Torsten and Lehmann, Heiko},
	month = sep,
	year = {2002},
	keywords = {Client/server, Java, Statistical computing, XploRe},
	pages = {315--328},
	file = {Submitted Version:C\:\\Users\\croch\\Zotero\\storage\\4MTZLBDF\\Kleinow and Lehmann - 2002 - ClientServer based Statistical Computing.pdf:application/pdf},
}

@article{baturay_relationship_2017,
	title = {The relationship among pre-service teachers computer competence, attitude towards computer-assisted education, and intention of technology acceptance},
	volume = {9},
	doi = {10.1504/IJTEL.2017.10003119},
	abstract = {Use of technology takes time and requires a paradigm change for teachers to adopt it. Teachers’ readiness, how they behave and perceive technology integration or adoption process is particularly critical. The current study investigates the relationship among pre-service teachers’ computer competence, attitude towards computer-assisted education, and intention of technology acceptance. The results indicate that computer ownership, the internet access and amount of daily computer use do not correlate with the attitude towards computer-assisted education (CAE). The internet access and computer ownership variables do not seem to have any relationship with the intention to technology acceptance. There is a significant and positive relationship among computer competence, attitude towards CAE, and intention to technology acceptance. Perceived usefulness and enjoyment have positive relationship with attitude towards CAE. Although perceived ease of use similarly has significant positive relationship with the attitude towards CAE, it does not predict the attitude towards it.},
	journal = {International Journal of Technology Enhanced Learning},
	author = {Baturay, Meltem Huri and Gökçearslan, {\c{S}}ahin and Ke, Fengfeng},
	month = may,
	year = {2017},
	pages = {1--13},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\RW9HREIU\\Baturay et al. - 2017 - The relationship among pre-service teachers comput.pdf:application/pdf},
}

@article{teo_factors_2011,
	title = {Factors influencing teachers' intention to use technology: {Model} development and test},
	volume = {57},
	shorttitle = {Factors influencing teachers' intention to use technology},
	doi = {10.1016/j.compedu.2011.06.008},
	abstract = {Among the key players in any effective integration of technology in teaching and learning is the teacher. Despite the research that has been conducted to examine the factors that explain teachers' intention to use technology, few have developed a model to statistically explain the interactions among these factors and how they influence teachers' intention to use technology. Five variables (perceived usefulness, perceived ease of use, subjective norm, facilitating conditions, and attitude towards use) and behavioural intention to use technology were used to build a research model in this study and structural equation modelling was used for parameter estimation and model testing. Self-reported data were gathered from 592 teachers from schools in Singapore. Results revealed a good model fit and of the nine hypotheses formulated in this study, eight were supported. Subjective norm was not found to be a significant influence on teachers' intention to use technology while the other four variables were.},
	journal = {Computers \& Education},
	author = {Teo, Timothy},
	month = dec,
	year = {2011},
	pages = {2432--2440},
}

@article{koutromanos_student_2015,
	title = {Student and in-service teachers' acceptance of spatial hypermedia in their teaching: {The} case of {HyperSea}},
	volume = {20},
	issn = {1360-2357},
	shorttitle = {Student and in-service teachers' acceptance of spatial hypermedia in their teaching},
	url = {https://doi.org/10.1007/s10639-013-9302-8},
	doi = {10.1007/s10639-013-9302-8},
	abstract = {The aim of this study was to use the Technology Acceptance Model (TAM) in order to investigate the factors that influence student and in-service teachers' intention to use a spatial hypermedia application, the HyperSea, in their teaching. HyperSea is a modern hypermedia environment that takes advantage of space in order to display content nodes and social media pages that can be dragged from the Internet. In total, 257 student and in-service teachers completed a survey questionnaire, measuring their responses to four constructs in the TAM. The results of student teachers' regression analysis showed that all components of the TAM were found to predict their intention to use HyperSea in their teaching. Perceived usefulness was the most important predictor in their attitude and intention. On the other hand, only attitude towards use had direct influence on teachers' intention. In addition, perceived usefulness influenced teachers' intention. Perceived ease of use in this study failed to emerge as a significant predictor of teachers' attitude and perceived usefulness. The results showed that the TAM in general is useful model for predicting and exploring the factors that influence student and in-service teachers' intention to use spatial hypermedia such as the HyperSea in their teaching in future. Results of the study are discussed in terms of increasing the intention of student and in service teachers to use spatial hypermedia in their teaching.},
	number = {3},
	urldate = {2022-10-03},
	journal = {Education and Information Technologies},
	author = {Koutromanos, George and Styliaras, Georgios and Christodoulou, Sotiris},
	month = sep,
	year = {2015},
	keywords = {Spatial hypermedia, Student and in-service teachers, TAM, Technology acceptance},
	pages = {559--578},
}

@article{venkatesh_user_2003,
	title = {User {Acceptance} of {Information} {Technology}: {Toward} a {Unified} {View}},
	volume = {27},
	issn = {02767783},
	shorttitle = {User {Acceptance} of {Information} {Technology}},
	url = {https://www.jstor.org/stable/10.2307/30036540},
	doi = {10.2307/30036540},
	language = {en},
	number = {3},
	urldate = {2022-09-26},
	journal = {MIS Quarterly},
	author = {{Venkatesh} and {Morris} and {Davis} and {Davis}},
	year = {2003},
	pages = {425},
	file = {Venkatesh et al. - 2003 - User Acceptance of Information Technology Toward .pdf:C\:\\Users\\croch\\Zotero\\storage\\E28YR3L7\\Venkatesh et al. - 2003 - User Acceptance of Information Technology Toward .pdf:application/pdf},
}

@inproceedings{schuster_user_2020,
	title = {A {User} {Study} on {AR}-assisted {Industrial} {Assembly}},
	doi = {10.1109/ISMAR-Adjunct51615.2020.00047},
	abstract = {The utilization of modern assistance system e.g. Augmented Reality (AR) has reached into industrial assembly scenarios. Beside the technical realization of AR assistance in the assembly scene the worker has to accept the new technology. Only both, user acceptance and technical user-interface design leads to an optimized overall system. Hence, this contribution gives a brief literature overview and analysis about AR acceptance and acceptance modeling. Then, a proprietary model for acceptance measurement is developed, which includes and synthesizes previous models (TAM and UTAUT) and simplifies them considerably for the purpose of industrial assembly. Following, a laboratory experiment is set-up in the FHWS c-Factory, which is a smart, IoT-based production environment. A survey and an assembly cycle time measurement is conducted to collect data to characterize AR assistance. The study participants assemble a toy truck once without and once with AR support. The evaluation shows that the mean assembly time decreases. The results show also, that AR is accepted by the participants supporting their work.},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	author = {Schuster, Florian and Sponholz, Uwe and Engelmann, Bastian and Schmitt, Jan},
	month = nov,
	year = {2020},
	keywords = {Analytical models, Assisted assembly, Augmented reality, Augmented Reality, Laboratories, Production, Time measurement, Toy manufacturing industry, User acceptance},
	pages = {135--140},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\NEFPC63X\\9288408.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\FLXNRH6M\\Schuster et al. - 2020 - A User Study on AR-assisted Industrial Assembly.pdf:application/pdf},
}

@inproceedings{koutromanos_mobile_2021,
	title = {Mobile {Augmented} {Reality} {Applications} in {Teaching}: {A} {Proposed} {Technology} {Acceptance} {Model}},
	shorttitle = {Mobile {Augmented} {Reality} {Applications} in {Teaching}},
	doi = {10.23919/iLRN52045.2021.9459343},
	abstract = {This study proposed MARAM, a mobile augmented reality acceptance model that determines the factors that affect teachers' intention to use AR applications in their teaching. MARAM extends TAM by adding the variables of perceived relative advantage, perceived enjoyment, facilitating conditions, and mobile self - efficacy. MARAM was tested in a pilot empirical study with 127 teachers who used educational mobile AR applications and developed their own ones. The results of regression analysis showed that MARAM can predict a satisfactory percentage of the variance in teachers' intention, attitude, perceived usefulness and perceived ease of use. Attitude, perceived usefulness, and facilitating conditions affected intention. Both perceived usefulness and perceived enjoyment affected attitude. Furthermore, perceived relative advantage and perceived enjoyment affected perceived usefulness. In addition, mobile self-efficacy and facilitating conditions affected perceived ease of use. However, perceived ease of use did not have any effect on attitude and perceived usefulness. MARAM could serve as the basis for future studies on teachers' acceptance of mobile AR applications and be expanded through the addition of other variables.},
	booktitle = {2021 7th {International} {Conference} of the {Immersive} {Learning} {Research} {Network} ({iLRN})},
	author = {Koutromanos, George and Mikropoulos, Tassos A.},
	month = may,
	year = {2021},
	keywords = {Augmented reality, education, Education, mobile augmented reality, Regression analysis, teachers, technology acceptance model, Technology acceptance model},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\KHU56LNZ\\9459343.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\82PQUTPJ\\Koutromanos and Mikropoulos - 2021 - Mobile Augmented Reality Applications in Teaching.pdf:application/pdf},
}

@inproceedings{utami_qualitative_2020,
	title = {Qualitative {Analysis}: {Acceptance} of {Android}-{Based} {Augmented} {Reality} {Technology} {Using} a {Mixture} of {Marker} and {Markerless} {Methods} as a {Product} {Differentiation} {Strategy}},
	shorttitle = {Qualitative {Analysis}},
	doi = {10.1109/ICIMCIS51567.2020.9354316},
	abstract = {An android-based application with Augmented Reality technology using a mixture of the marker and markerless methods (MaDa AR) is one of the implementations of AMDK MaDa product differentiation strategy. This research aims to get an idea of the process of consumer acceptance of the design and features of applications that have been developed based on two factors of the Technology Acceptance Model (TAM) namely, perceived usefulness and perceived ease of use. The approach in this study is qualitative so that the data obtained is more in-depth, credible, and meaningful so that research objectives can be achieved. To get an overview of the phenomena related to the study in its entirety and depth, the researchers conducted observations, documentation studies, and live interviews with respondents who fit with the research criteria. The results of this study showed in the user's acceptance of this application, in addition to technology factors namely perceived factor of usefulness and perceived ease of use of TAM concept, other factors also found, namely knowledge and motivation factors of the user as well as factors of previous user experience.},
	booktitle = {2020 {International} {Conference} on {Informatics}, {Multimedia}, {Cyber} and {Information} {System} ({ICIMCIS})},
	author = {Utami, Athika Dwi Wiji and Nugroho, Rizky Aditya and Noviyanti, Masyitah},
	month = nov,
	year = {2020},
	keywords = {Augmented reality, Augmented Reality, Technology acceptance model, Informatics, Interviews, Multimedia systems, Perceived Ease of Use, Perceived Usefulness, Product Differentiation, Qualitative, System analysis and design, User experience},
	pages = {247--252},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\NEGC4CNY\\9354316.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\5FLN93CY\\Utami et al. - 2020 - Qualitative Analysis Acceptance of Android-Based .pdf:application/pdf},
}

@inproceedings{ganapathy_mar_2011,
	title = {{MAR} shopping assistant usage: {Delay}, error, and utility},
	shorttitle = {{MAR} shopping assistant usage},
	doi = {10.1109/VR.2011.5759471},
	abstract = {This poster will present findings from a study of a shopping assistant prototype with simulated augmented reality information. The goal of the study was to find out the acceptable level of delay in presentation of augmented information and the acceptable rate of error of the information presented. Twelve participants interacted with a Samsung Omnia™ smartphone that presented a wine shopping scenario under several levels of delay in showing product information. Participants indicated their willingness to wait for each delay they experienced. Participants also answered a survey about which types of products they would want a shopping assistant application to assist with.},
	booktitle = {2011 {IEEE} {Virtual} {Reality} {Conference}},
	author = {Ganapathy, Subhashini and Anderson, Glen J. and Kozintsev, Igor V.},
	month = mar,
	year = {2011},
	note = {ISSN: 2375-5334},
	keywords = {Augmented reality, Computational modeling, delay, Delay, error, latency, Mobile augmented reality, Mobile handsets, Navigation, Presses, Prototypes, shopping, usage model},
	pages = {207--208},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\55ADBFGJ\\5759471.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\HSW4INHJ\\Ganapathy et al. - 2011 - MAR shopping assistant usage Delay, error, and ut.pdf:application/pdf},
}

@inproceedings{olsson_online_2011,
	title = {Online user survey on current mobile augmented reality applications},
	doi = {10.1109/ISMAR.2011.6092372},
	abstract = {Augmented reality (AR) as an emerging technology in the mobile computing domain is becoming mature enough to engender publicly available applications for end users. Various commercial applications have recently been emerging in the mobile consumer domain at an increasing pace — Layar, Junaio, Google Goggles, and Wikitude are perhaps the most prominent ones. However, the research community lacks an understanding of how well such timely applications have been accepted, what kind of user experiences they have evoked, and what the users perceive as the weaknesses of the various applications overall. During the spring of 2011 we conducted an online survey to study the overall acceptance and user experience of the mobile AR-like consumer applications currently existing on the market. This paper reports the first analyses of the qualitative and quantitative survey data of 90 respondents. We highlight an extensive set of user-oriented issues to be considered in developing the applications further, as well as in directing future user research in AR. The results indicate that the experiences have been inconsistent: generally positive evaluations are overshadowed by mentions of applications' pragmatic uselessness in everyday life and technical unreliability, as well as excessive or limited and irrelevant content.},
	booktitle = {2011 10th {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Olsson, Thomas and Salo, Markus},
	month = oct,
	year = {2011},
	keywords = {Augmented reality, augmented reality, Browsers, Cameras, Context, end user application, evaluation, Image recognition, Mobile communication, online survey, user acceptance, user experience, Visualization},
	pages = {75--84},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\62AIT5KQ\\6162874.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\54MVRPXC\\Olsson and Salo - 2011 - Online user survey on current mobile augmented rea.pdf:application/pdf},
}

@article{rodrigues_mobile_2019,
	title = {Mobile {Five} {Senses} {Augmented} {Reality} {System}: {Technology} {Acceptance} {Study}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {Mobile {Five} {Senses} {Augmented} {Reality} {System}},
	doi = {10.1109/ACCESS.2019.2953003},
	abstract = {The application of the most recent technologies is fundamental to add value to tourism experiences, as well as in other economic sectors. Mobile Five Senses Augmented Reality (M5SAR) system is a mobile guide instrument for cultural, historical, and museum events. In order to realize the proclaimed five senses, the system has two main modules: a (i) mobile application which deals mainly with the senses of sight and hearing, using for that the mobile device camera to recognize and track on-the-fly (museum's) objects and give related information about them; and a (ii) portable device capable of enhancing the augmented reality (AR) experience to the full five senses through the stimulus of touch, taste, and smell, by associating itself to the users' smartphone or tablet. This paper briefly presents the system's architecture but, the main focus is on the analysis of the users' acceptance for this technology, namely the AR (software) application, and its integration with the (hardware) device to achieve the five senses AR. Results show that social influence, effort expectancy, and facilitating conditions are the key constructs that drive the users to accept and M5SAR's technology.},
	journal = {IEEE Access},
	author = {Rodrigues, João M. F. and Ramos, Célia M. Q. and Pereira, João A. R. and Sardo, João D. P. and Cardoso, Pedro J. S.},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {TAM, Augmented reality, Augmented Reality, Mobile handsets, Auditory system, Computer architecture, five senses, Hardware, Layout, Mobile applications, UTAUT},
	pages = {163022--163033},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\XIFZFXWB\\8896028.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\8GSRI8N9\\Rodrigues et al. - 2019 - Mobile Five Senses Augmented Reality System Techn.pdf:application/pdf},
}

@inproceedings{thomas_is_2021,
	title = {Is {Functionality} {All} {That} {Matters}? {Examining} {Everyday} {User} {Opinions} of {Augmented} {Reality} {Devices}},
	shorttitle = {Is {Functionality} {All} {That} {Matters}?},
	doi = {10.1109/VRW52623.2021.00050},
	abstract = {How users feel towards Augmented Reality (AR) is often shaped by the context of use. This paper reports from a study with 112 participants on how users experience AR in everyday situations. The respondents in an online survey were queried about comfort, aesthetics, functionality, privacy, and physical limitations. The responses revealed a range of opinions, from general enjoyment to key issues and features that users are concerned with, such as pain and tiredness, device size, social acceptance of AR devices, and accessibility. Considerations for future work regarding these issues are discussed. These include balancing functionality with appearance, involving a variety of users in the design process, and focusing on devices that the everyday person is likely to use. Overall users appear keen to see AR device improvements resulting in more practical and accessible devices.},
	booktitle = {2021 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	author = {Thomas, Derianna and Holmquist, Lars Erik},
	month = mar,
	year = {2021},
	keywords = {User experience, Conferences, Focusing, Human-centered computing, Mixed/augmented reality, Pain, Privacy, Three-dimensional displays, User interfaces, User studies},
	pages = {232--237},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\3L9DUVMH\\9419236.html:text/html},
}

@inproceedings{bhutta_next_2015,
	title = {The next problems to solve in augmented reality},
	doi = {10.1109/ICICT.2015.7469490},
	abstract = {Augmented reality (AR) is a growing phenomenon. We are on the verge of ubiquitously adopting Augmented Reality (AR) technologies to enhance our perception and help us see, hear, and feel our environments in new and enriched ways. AR will really change the way people see the universe. This paper provides a review on classification of different augmented reality challenges ranges from human factors to hard problem of law and policy which aims to explore new challenges and issues for the acceptance of AR technology.},
	booktitle = {2015 {International} {Conference} on {Information} and {Communication} {Technologies} ({ICICT})},
	author = {Bhutta, Zunaira Ilyas and Umm-e-Hani, Syedda and Tariq, Iqra},
	month = dec,
	year = {2015},
	keywords = {Augmented reality, Augmented Reality, Mobile communication, Visualization, Privacy, User interfaces, AR acceptance, Augmented Reality technologies, challenges, Computers},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\7CS2T37T\\7469490.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\CYQSMWL3\\Bhutta et al. - 2015 - The next problems to solve in augmented reality.pdf:application/pdf},
}

@inproceedings{meyer_evaluating_2021,
	title = {Evaluating {User} {Acceptance} using {WebXR} for an {Augmented} {Reality} {Information} {System}},
	doi = {10.1109/VRW52623.2021.00091},
	abstract = {Augmented Reality has a long history and has seen major technical advantages in the last years. With WebXR, a new web standard, Mobile Augmented Reality (MAR) applications are now available in the web browser. With our work, we implemented an Augmented Reality Information System and conducted a case study to evaluate the user acceptance of such an application build with WebXR. Our results indicate that the user acceptance regarding web-based MAR applications for our specific use case seems to be given. With our proposed architecture we also lay the foundation for other AR information systems.},
	booktitle = {2021 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	author = {Meyer, Fabian and Gehrke, Christian and Schäfer, Michael},
	month = mar,
	year = {2021},
	keywords = {Augmented reality, Augmented Reality, Browsers, Conferences, Three-dimensional displays, User interfaces, History, Information System, Tracking, User Accpetance, WebXR},
	pages = {418--419},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\TFFZLJ5L\\9419122.html:text/html},
}

@inproceedings{souza-herod_augmented_2021,
	title = {Augmented {Reality} {Shopping} {Framework}},
	doi = {10.1109/SoutheastCon45413.2021.9401926},
	abstract = {Augmented Reality (AR) is becoming an important computing platform with the potential of enhancing the experiences of everyday users. One of those experiences is shopping. When customers buy any product, it is very discouraging to locate vital information such as the expiration date. This paper discusses an AR solution for shoppers that want to elevate their shopping experience in general by an enhanced information search. The solution can be also expanded in the future to assist shoppers who are suffering from a reduced visual sense. A proof of concept application is developed to test the solution, where we simulate a medicine shopping scenario. The application we developed on the HoloLens uses the Vuforia SDK to tag products and display information about these products. In addition, it contains elements that can alter the text size thus providing assistive support option for the visually impaired in the future. We predict that the convenience of having information displayed next to products as well as the ability to control the text size will make shopping more pleasant. Our architecture shows promise for a full assistive technology for the visually impaired that could be vital for the community, and there are future plans to port it to a different platform such as Android or iOS. Moreover, the architecture harnesses the ability to customize the information that the user can select to view, such as instructions, ingredients, and/or users' review. We conclude the paper with our look into the future.},
	booktitle = {{SoutheastCon} 2021},
	author = {Souza-Herod, Phelippe and Hamam, Abdelwahab},
	month = mar,
	year = {2021},
	note = {ISSN: 1558-058X},
	keywords = {Augmented reality, Augmented Reality, Visualization, Computer architecture, Assistive, Assistive technology, HoloLens, Shopping, Vuforia},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\KQMGIBPK\\9401926.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\DVLCJJFP\\Souza-Herod and Hamam - 2021 - Augmented Reality Shopping Framework.pdf:application/pdf},
}

@article{wasson_ethnography_2000,
	title = {Ethnography in the {Field} of {Design}},
	volume = {59},
	issn = {0018-7259},
	url = {https://www.jstor.org/stable/44127235},
	abstract = {Members of the design profession help develop new products and services of many kinds, and they are centrally concerned with satisfying the needs of users of their products. Ethnography appeals to designers because it provides a window onto the ways consumers interact with products in their everyday lives. The paper provides an overview of this extension of applied anthropology to a new domain. It traces how ethnography became known to designers and the transmission of particular research traditions that have shaped the practice of "ethnography" in the design field. Ethnomethodology, conversation analysis, and activity theory have been prominent theoretical influences. Most data-gathering methods are characterized by the use of videotape. As an example, I describe the research practices of one design firm, formerly known as E-Lab LLC, now part of Sapient Corporation.},
	number = {4},
	urldate = {2022-09-19},
	journal = {Human Organization},
	author = {Wasson, Christina},
	year = {2000},
	note = {Publisher: Society for Applied Anthropology},
	pages = {377--388},
}

@inproceedings{sun_segmentation_2019,
	title = {Segmentation based {Non}-learning {Product} {Detection} for {Product} {Recognition} on {Store} {Shelves}},
	doi = {10.1109/NICOInt.2019.00009},
	abstract = {The arrangement of products on store shelves can refer to commercial contracts, sale achievement, and customer satisfaction. At present, clerks check the arrangement manually, which spends time, costs human resource significantly, and can disturb shopping customers. Although automatic methods via computer vision (often incorporating machine learning) can solve the issue, the existing methods need single product template images for detection, facing the difficult collection of master images and the frequent upgrade of products. In this paper, we propose to detect products on store shelves by segmenting the shelves horizontally and vertically without template images and machine learning. The horizontal segmentation is based on clapboard detection via casting lateral gradient votes. The vertical segmentation contains the linear region of interest (ROI) optimization and shadow detection by longitudinal gradient grouping. In experiments, we compare our method with the only existing non-template method, and our method outperforms the existing method.},
	booktitle = {2019 {Nicograph} {International} ({NicoInt})},
	author = {Sun, Haitian and Hanata, Kenji and Sato, Hideomi and Tsuchitani, Ichiro and Akashi, Takuya},
	month = jul,
	year = {2019},
	keywords = {linear-optimization, product-detection, product-recognition},
	pages = {9--16},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\QAQW7BVA\\8949198.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\TC29LLNC\\Sun et al. - 2019 - Segmentation based Non-learning Product Detection .pdf:application/pdf},
}

@inproceedings{omar_correlation_2010,
	title = {The correlation between {Label} {Messages} and {Labeling} {Effectiveness}},
	doi = {10.1109/CSSR.2010.5773918},
	abstract = {Labeling can perform many different functions, like the identification, description or promotion of food products, however based on research the main purpose of food labeling is to inform consumers on the content and the nutrients of the food. All food labels need to have minimum amount of mandatory or legally set information, but a producer may add any voluntary but correct information should they feel that the information stated would be off an advantage and that would lead a consumer to purchase the product. Food producers also would at times, use terms which would only be understood by experts and non experts would be left guessing and interpreting the terms themselves. Consumers also consider food labeling to be very important component of their lifestyle and regard nutrition as a positive attribute to the products. With that, this study attempts to see the correlation between Label Messages and Label Effectiveness. These findings will provide a view on what is the correlation between the label messages and its effectiveness. This would also assist manufaturers to identify on what information or messages which would have an impact before consumers makes their buying decisions.},
	booktitle = {2010 {International} {Conference} on {Science} and {Social} {Research} ({CSSR} 2010)},
	author = {Omar, Maznah Wan and Ali, Mohd Noor Mohd and Zakaria, Azfahanee and AlHady, Syed Mohammed AlHady Syed Ahmad},
	month = dec,
	year = {2010},
	keywords = {Education, Business, Canned Food, Correlation, Food products, Label Effectiveness, Label Messages, Labeling, Media, Reliability},
	pages = {913--915},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\5QSHWZN4\\5773918.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\ZS5VZ6XX\\Omar et al. - 2010 - The correlation between Label Messages and Labelin.pdf:application/pdf},
}

@inproceedings{nute_product_2019,
	title = {Product {Markings} and {Labels}},
	doi = {10.1109/ISPCE.2019.8771341},
	abstract = {Product markings and labels provide information about the product, installation, and use. The markings and labels can also provide warnings to avoid hazardous energy transfer to a body part. The product safety aspects of markings for identification, ratings, functions, connections, and warnings are described.},
	booktitle = {2019 {IEEE} {International} {Symposium} on {Product} {Compliance} {Engineering} ({ISPCE})},
	author = {Nute, Richard},
	month = may,
	year = {2019},
	note = {ISSN: 2474-2481},
	keywords = {Batteries, Fuses, IEC Standards, Plugs, product labels, product markings, product safety, Safety, symbols, Voltage control, warnings},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\HRRNU5C2\\8771341.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\7JMRN3DK\\Nute - 2019 - Product Markings and Labels.pdf:application/pdf},
}

@misc{noauthor_machine_nodate,
	title = {Machine {Learning} – {Amazon} {Web} {Services}},
	url = {https://aws.amazon.com/sagemaker/},
	abstract = {Build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.},
	language = {en-US},
	urldate = {2022-09-19},
	journal = {Amazon Web Services, Inc.},
	file = {Snapshot:C\:\\Users\\croch\\Zotero\\storage\\7EWCY859\\sagemaker.html:text/html},
}

@misc{noauthor_fooddata_nodate,
	title = {{FoodData} {Central}},
	url = {https://fdc.nal.usda.gov/},
	urldate = {2022-09-19},
	file = {FoodData Central:C\:\\Users\\croch\\Zotero\\storage\\QSQ3L9UY\\fdc.nal.usda.gov.html:text/html},
}

@inproceedings{alvarez_marquez_acceptance_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Acceptance of an {AR}-{Based} {In}-{Store} {Shopping} {Advisor} - the {Impact} of {Psychological} {User} {Characteristics}},
	isbn = {978-3-030-85623-6},
	doi = {10.1007/978-3-030-85623-6_28},
	abstract = {We present a study on the acceptance of augmented reality-based product comparison and recommending in a physical store context. An online study was performed, in which a working prototype for head-mounted displays, developed in previous research, was used to showcase the concept. The survey included questionnaires to assess shopping behaviour, decision styles and propensity to adopt new technologies of the participants. A cluster analysis of these psychological traits reveals the existence of different types of customers, who also differ on their assessment of the system. While the technology adoption propensity index is the better predictor of the acceptance of an augmented reality shopping advisor, the results suggest that factors such as the user’s previous experience, a high experiential chronic shopping orientation, or an intuitive decision style have a significant impact on it as well. Thus, predicting user acceptance solely based on one of the investigated psychological traits may be unreliable, and studying them in conjunction can provide a more accurate estimation.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2021},
	publisher = {Springer International Publishing},
	author = {Álvarez Márquez, Jesús Omar and Ziegler, Jürgen},
	editor = {Ardito, Carmelo and Lanzilotti, Rosa and Malizia, Alessio and Petrie, Helen and Piccinno, Antonio and Desolda, Giuseppe and Inkpen, Kori},
	year = {2021},
	keywords = {Technology acceptance, Augmented reality, Retailing, Shopping advisors},
	pages = {457--479},
}

@article{ahn_supporting_2015,
	title = {Supporting {Healthy} {Grocery} {Shopping} via {Mobile} {Augmented} {Reality}},
	volume = {12},
	issn = {1551-6857},
	url = {https://doi.org/10.1145/2808207},
	doi = {10.1145/2808207},
	abstract = {Augmented reality (AR) applications have recently become popular on modern smartphones. We explore the effectiveness of this mobile AR technology in the context of grocery shopping, in particular as a means to assist shoppers in making healthier decisions as they decide which grocery products to buy. We construct an AR-assisted mobile grocery-shopping application that makes real-time, customized recommendations of healthy products to users and also highlights products to avoid for various types of health concerns, such as allergies to milk or nut products, low-sodium or low-fat diets, and general caloric intake. We have implemented a prototype of this AR-assisted mobile grocery shopping application and evaluated its effectiveness in grocery store aisles. Our application's evaluation with typical grocery shoppers demonstrates that AR overlay tagging of products reduces the search time to find healthy food items, and that coloring the tags helps to improve the user's ability to quickly and easily identify recommended products, as well as products to avoid. We have evaluated our application's functionality by analyzing the data we collected from 15 in-person actual grocery-shopping subjects and 104 online application survey participants.},
	number = {1s},
	urldate = {2022-09-18},
	journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
	author = {Ahn, Junho and Williamson, James and Gartrell, Mike and Han, Richard and Lv, Qin and Mishra, Shivakant},
	month = oct,
	year = {2015},
	keywords = {Augmented reality, grocery shopping, mobile health, nutrition, recommendation},
	pages = {16:1--16:24},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\HIKFDYTD\\Ahn et al. - 2015 - Supporting Healthy Grocery Shopping via Mobile Aug.pdf:application/pdf},
}

@inproceedings{roddiger_armart_2018,
	address = {New York, NY, USA},
	series = {{UbiComp} '18},
	title = {{ARMart}: {AR}-{Based} {Shopping} {Assistant} to {Choose} and {Find} {Store} {Items}},
	isbn = {978-1-4503-5966-5},
	shorttitle = {{ARMart}},
	url = {https://doi.org/10.1145/3267305.3267631},
	doi = {10.1145/3267305.3267631},
	abstract = {Supermarkets offer a wide range of products which makes it challenging for consumers to choose between the different options and find the items they are looking for. Augmented Reality (AR) applications, however, have a high potential to enrich real-world objects with information which can be leveraged to improve this process. We developed an application that runs on a regular smartphone and helps users to choose between packaged groceries based on factors such as calories or sugar, rated on a scale from red (bad) to green (good). Compared to previous work, there is no need for a priori knowledge about product locations making the system suitable for many use cases. Moreover, information maps precisely onto the outline of the product's and not on the approximate shelf. To do so, no modifications of the objects, such as specialized tags, are necessary. Additionally, users can find items just by entering the name. Highlighting the packaging virtually helps to find the desired product. It is also possible to make a binary distinction between groceries that contain specific ingredients.},
	urldate = {2022-09-18},
	booktitle = {Proceedings of the 2018 {ACM} {International} {Joint} {Conference} and 2018 {International} {Symposium} on {Pervasive} and {Ubiquitous} {Computing} and {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Röddiger, Tobias and Doerner, Dominik and Beigl, Michael},
	month = oct,
	year = {2018},
	keywords = {shopping, augmented reality, assistant, smartphone},
	pages = {440--443},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\HV5QLHZE\\Röddiger et al. - 2018 - ARMart AR-Based Shopping Assistant to Choose and .pdf:application/pdf},
}

@inproceedings{jayagoda_smarket_2021,
	title = {{SMARKET} - {Shopping} in {Supercenters} ({Hypermarkets}) with {Augmented} {Reality}},
	doi = {10.1109/ICCCA52192.2021.9666359},
	abstract = {Not so long ago, online shopping for groceries, electronics, and furniture items seemed futuristic. But today, it has become a norm to order requisites through online platforms using smart devices and deliver them to customers' doorstep. With the emerge of technologies such as artificial intelligence, machine learning, deep learning, augmented reality, retail becomes progressively effortless. One such emerging futuristic technology involved recently in online shopping is Augmented Reality (AR) which is rapidly adopted by many industries. In multi-story supercenters, also known as “Hypermarkets”, the customer often feels lost due to difficulty in finding exactly what they looking for, and also in conventional online shopping, often customers are in two minds whether to purchase an item or not since it lacks the proper visualization, touch, and feel of the product. In this research study, we propose a mobile-based solution with augmented reality, which assists the customer when shopping in-store as well as when shopping online to mitigate the difficulties and hesitancies faced while shopping. The results are commendable with 96.21 \% accuracy in suggesting visually similar items and 89.59\% accuracy in detecting emotional implications of product reviews.},
	booktitle = {2021 {IEEE} 6th {International} {Conference} on {Computing}, {Communication} and {Automation} ({ICCCA})},
	author = {Jayagoda, N.M. and Jayawardana, O.R and Welivita, W.W.T.P and Weerasinghe, L and Dassanayake, T},
	month = dec,
	year = {2021},
	note = {ISSN: 2642-7354},
	keywords = {Visualization, Conferences, Algorithms, AugmentedReality, Automation, Convolutional Neural Networks, Deep learning, Electronic commerce, Industries, Natural Language Processing, Smart devices, Supercenters},
	pages = {771--776},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\WH2GZCDJ\\9666359.html:text/html},
}

@inproceedings{riedlinger_ar_2020,
	title = {{AR} {Mini}-{Games} for {Supermarkets}},
	doi = {10.1109/ISMAR-Adjunct51615.2020.00020},
	abstract = {We present an Augmented Reality (AR) application intended for use in supermarkets, with the primary goal to bring fun and digital engagement through AR mini-games to the customers while shopping. We believe that our approach can be extended and scaled up by integrating mini-games into existing shopping apps in the future.},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	author = {Riedlinger, Urs and Oppermann, Leif and Uzun, Yücel and Brosda, Constantin},
	month = nov,
	year = {2020},
	keywords = {Augmented reality, Human-centered computing, Mixed / augmented reality, Mobile computing, Ubiquitous and mobile computing systems and tools},
	pages = {19--20},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\GWASBJSY\\9287827.html:text/html},
}

@inproceedings{li_profi_2013,
	address = {New York, NY, USA},
	series = {{UbiComp} '13 {Adjunct}},
	title = {{ProFi}: design and evaluation of a product finder in a supermarket scenario},
	isbn = {978-1-4503-2215-7},
	shorttitle = {{ProFi}},
	url = {https://doi.org/10.1145/2494091.2496007},
	doi = {10.1145/2494091.2496007},
	abstract = {This paper presents the design and evaluation of ProFi, a PROduct FInding assistant in a supermarket scenario. We explore the idea of micro-navigation in supermarkets and aim at enhancing visual search processes in front of a shelf. In order to assess the concept, a prototype is built combining visual recognition techniques with an Augmented Reality interface. Two AR patterns (circle and spotlight) are designed to highlight target products. The prototype is formally evaluated in a controlled environment. Quantitative and qualitative data is collected to evaluate the usability and user preference. The results show that ProFi significantly improves the users' product finding performance, especially when using the circle pattern, and that ProFi is well accepted by users.},
	urldate = {2022-09-18},
	booktitle = {Proceedings of the 2013 {ACM} conference on {Pervasive} and ubiquitous computing adjunct publication},
	publisher = {Association for Computing Machinery},
	author = {Li, Ming and Arning, Katrin and Bremen, Luisa and Sack, Oliver and Ziefle, Martina and Kobbelt, Leif},
	month = sep,
	year = {2013},
	keywords = {ar interface, micro-navigation, shopping assistant, supermarket scenario, user study, visual tracking},
	pages = {977--984},
}

@inproceedings{xia_parashop_2020,
	title = {{ParaShop}: {A} {Mobile} {AR} {App} in {Assisting} {People} with {ASD} in {Shopping}},
	shorttitle = {{ParaShop}},
	doi = {10.1109/URTC51696.2020.9668867},
	abstract = {Approximately 1 in 160 children worldwide is diagnosed with Autism Spectrum Disorder (ASD). ASD prevalence is on the rise in the United States. Virtual reality (VR) techniques have been tried in several studies to improve the shopping skills of people with ASD. However, in these VR applications, the effectiveness in training people with ASD in shopping has never been tested in the real-world environments. Our studies show that individuals with ASD become anxious when exposed to a new environment such as a supermarket, without knowing what to do next. Also, VR applications are less accessible, portable, or affordable compared to the emerging mobile augmented reality (AR) applications. Therefore, we have created a mobile AR application that augments real shopping scenes with visual-audio annotations via object recognition, barcode reading, and automatic categorization. Through a user-friendly visual interface, the app can help people with ASD learn shopping skills effectively, by guiding them through the shopping process step by step in a real environment with AR. A short YouTube demo video of ParaShop can be found at https://youtu.be/77tp3julNZ0.},
	booktitle = {2020 {IEEE} {MIT} {Undergraduate} {Research} {Technology} {Conference} ({URTC})},
	author = {Xia, Mengting and Chen, Nan and Tang, Yuemin and Zhu, Zhigang},
	month = oct,
	year = {2020},
	keywords = {Augmented reality, Augmented Reality, Visualization, Conferences, Annotations, Assistive Technology, Autism, Autism Spectrum Disorder, Object recognition, Object Recognition, Text Classification, Training},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\U5ED2JYY\\9668867.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\2EVU27AI\\Xia et al. - 2020 - ParaShop A Mobile AR App in Assisting People with.pdf:application/pdf},
}

@inproceedings{jayananda_augmented_2018,
	title = {Augmented {Reality} {Based} {Smart} {Supermarket} {System} with {Indoor} {Navigation} using {Beacon} {Technology} ({Easy} {Shopping} {Android} {Mobile} {App})},
	doi = {10.1109/ICIAFS.2018.8913363},
	abstract = {Augmented reality (AR) applications have recently become popular on modern smartphones. We explore the effectiveness of this mobile AR technology in the context of grocery shopping, in particular as a means to assist shoppers in navigating to the desired products and making healthier and beneficial decisions as they decide which grocery products to buy and even do shopping while staying at home. A supermarket is a customer base premises; means the customer is the one who decides what he is going to purchase and the customer satisfaction may be crucial. In-house shopping in supermarkets has earned popularity among majority of the customers and at the same time most of the customers looking for remote shopping which they can do get the shopping experience just sitting at home. Shopping malls has combined with the IT industry and create more innovative and creative apps, which are beneficial for both the customer and seller parties. So, the main objective of this work is to design a fully functional mobile application that has an innovative positioning and navigation system using AR core technology and Augmented Reality. The other major parts of this application are customer base shopping list handling, personalized recommendations by object detection using AR and remote shopping. Overall the scope of study involves research on AR core technology, Augmented Reality and other additional technologies. The idea of this work can be broadly applied to mobile devices such as mobile phones as an added physical shopping mall functionality using above mention technologies. The proposed Easy Shopping android based mobile app has been tested at the KEELS supermarket in Sri Lanka.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Information} and {Automation} for {Sustainability} ({ICIAfS})},
	author = {Jayananda, P.K.V and Seneviratne, D.H.D. and Abeygunawardhana, Pradeep and Dodampege, L.N and Lakshani, A.M.B},
	month = dec,
	year = {2018},
	note = {ISSN: 2151-1810},
	keywords = {Augmented reality, Industries, Android, AR core, AR-Augmented Reality, Bluetooth, Customer satisfaction, Easy Shopping, Indoor navigation, Information technology},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\P9CXSQQW\\8913363.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\JXLWARH2\\Jayananda et al. - 2018 - Augmented Reality Based Smart Supermarket System w.pdf:application/pdf},
}

@inproceedings{alhamdan_extended_2020,
	title = {Extended {Abstract}: {CoShopper} - {Leveraging} {Artificial} {Intelligence} for an {Enhanced} {Augmented} {Reality} {Grocery} {Shopping} {Experience}},
	shorttitle = {Extended {Abstract}},
	doi = {10.1109/AIVR50618.2020.00069},
	abstract = {This paper presents a system that integrates Artificial Intelligence (AI) methods with Augmented Reality (AR) techniques to enhance grocery shopping experience through the use of smart glasses. Our proposed framework deploys a Convolutional Neural Network (CNN) object detection model that allows for item identification. By simultaneously retrieving data from a large nutrition database, personal medical reports, and other grocery store related datasets, our intelligent system is able to provide user-centric nutrition facts, health and wellness tips, and unhealthy selection warnings that are augmented on a real time broadcasting of the smart glasses. Our state-of-the-art framework CoShopper demonstrates high accuracy in detecting grocery items, improves product selection, increases cost efficiency, and reduces the time spent in the process. Video demo of CoShopper can be viewed at [shorturl.at/mqIPX]},
	booktitle = {2020 {IEEE} {International} {Conference} on {Artificial} {Intelligence} and {Virtual} {Reality} ({AIVR})},
	author = {Alhamdan, Yasmeen and Alabachi, Saif and Khan, Naimul},
	month = dec,
	year = {2020},
	keywords = {Augmented Reality, Visualization, Object recognition, Training, Artificial Intelligence, Deep Learning, Medical diagnostic imaging, Real-time systems, Smart glasses, Smart Glasses, Smart Grocery Shopping, Streaming media},
	pages = {337--338},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\K58GQYT2\\9319053.html:text/html},
}

@inproceedings{timchenko_augmented_2020,
	title = {Augmented {Reality} in {Web}: {Results} and {Challenges}},
	shorttitle = {Augmented {Reality} in {Web}},
	doi = {10.1109/DSMP47368.2020.9204240},
	abstract = {The paper presents basic concepts of augmented reality applications and challenges in building them in the web. We describe the technical and algorithmic stack required to develop, implement and deploy the augmented reality application. Theoretical concepts behind marker detection and tracking are discussed. Two different pipelines are implemented: server-based with algorithms execution in the cloud and completely front-end solution that runs on a user device. We show advantages and disadvantages of each approach and analyze experimental results as well.},
	booktitle = {2020 {IEEE} {Third} {International} {Conference} on {Data} {Stream} {Mining} \& {Processing} ({DSMP})},
	author = {Timchenko, Ruslan and Grechnyev, Oleksiy and Skuratovskyi, Sergiy and Chyrka, Yurii and Gorovyi, Ievgen},
	month = aug,
	year = {2020},
	keywords = {Augmented reality, augmented reality, Browsers, Cameras, Three-dimensional displays, visual tracking, image marker, Pipelines, Solid modeling, Transmission line matrix methods, webAR},
	pages = {211--216},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\JXUWYZGN\\9204240.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\UXEL34WQ\\Timchenko et al. - 2020 - Augmented Reality in Web Results and Challenges.pdf:application/pdf},
}

@inproceedings{nitika_study_2021,
	title = {A study of {Augmented} {Reality} performance in web browsers ({WebAR})},
	doi = {10.1109/ICCMST54943.2021.00065},
	abstract = {The extensive development of augmented reality (AR) is ascending excessively, Web-based augmented reality (WebAR) is an advent to users which stamp out the friction of downloading an application based on AR, by simply publishing the 2D/3D content in web browsers to be accessible by customised URL. This paper provides a visionary as well as practical understanding of specialized improvement in the WebAR. We examine current trends which help eliminates the agitation of slacken experience. A practical analysis is done using ar.js, integration of Web graphic library with three.js for overlaying digital content with the help of marker. Furthermore, the browser + cloud solution will provide exclusive network capabilities by conquering the service element provided by web AR from the remote cloud server to the edge server effectively to render 3D model using WebRTC, object recognition algorithm integrated with profound JavaScript libraries which will remove the slacken performance optimization when a digital 2D/3D content is rendered in the user device's camera.},
	booktitle = {2021 2nd {International} {Conference} on {Computational} {Methods} in {Science} \& {Technology} ({ICCMST})},
	author = {Nitika, Nitika and Sharma, Tanuja Kumari and Rajvanshi, Saumya and Kishore, Keshav},
	month = dec,
	year = {2021},
	keywords = {Augmented Reality, Browsers, Three-dimensional displays, Solid modeling, ar.js, Libraries, Productivity, Publishing, three.js, Uniform resource locators, Web-based augmented reality, WebGL, WebRTC},
	pages = {281--286},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\PPGP3A8Z\\9784629.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\8BSX23T5\\Nitika et al. - 2021 - A study of Augmented Reality performance in web br.pdf:application/pdf},
}

@inproceedings{lee_ar_2012,
	title = {{AR} {UX} design: {Applying} {AEIOU} to handheld augmented reality browser},
	shorttitle = {{AR} {UX} design},
	doi = {10.1109/ISMAR-AMH.2012.6484000},
	abstract = {With maturing technologies and availability of the sensor-enriched device, the driving force behind handheld augmented reality (HAR) technology will be leaning towards the experience technology can bring. Though attentions are gathered on usability and conventions for this technology, the user experience cannot be ignored. It will be more commonly available in the hands of the public and become a technology that is not solely used by experts. It will be important to approach the technology with friendlier and more user-centered focus to bring it out of research labs and into people's life. In this paper, we will introduce design exploration constructs inspired from a method that is commonly used in the field of the industrial design to guide designers of HAR application to explore different aspects of user experience. The purpose of proposing AEIOU is to provide a platform to create encompassing user experience that is beyond the usability considerations or the existing design conventions. The advantage of having such a platform is to provide a starting ground for discussion and betterment of HAR application. The use of these constructs is discussed in relation to the design process of AR browser.},
	booktitle = {2012 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} - {Arts}, {Media}, and {Humanities} ({ISMAR}-{AMH})},
	author = {Lee, Mandi Jieying and Wang, Yuan and Duh, Henry Been-Lirn},
	month = nov,
	year = {2012},
	note = {ISSN: 2381-8360},
	keywords = {Augmented reality, Browsers, user experience, Layout, Availability, Buildings, Educational institutions, Interaction and interactivity, practice and methods, Usability},
	pages = {99--100},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\JEFRG53J\\6484000.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\GXLMEB5G\\Lee et al. - 2012 - AR UX design Applying AEIOU to handheld augmented.pdf:application/pdf},
}

@inproceedings{nasri_user_2020,
	title = {The {User} {Experience} effect of {Applying} {Floating} {Action} {Button} ({FAB}) into {Augmented} {Reality} {Anatomy} {Cranium} {Media} {Learning} {Prototype}},
	doi = {10.1109/ISRITI51436.2020.9315459},
	abstract = {A learning media's success is determined by two factors, namely the instructional design and user interface design. Most of the existing AR anatomy-based teaching media still do not pay attention to the learning media's UI and UX design. Elements such as navigation menus, text, icons, buttons, and others still accumulate, leading to the interface feel dense. This problem also can shift the user's attention when using this learning media. We tried to apply the FAB (Floating Action Button) to high-fidelity AR-based anatomy learning media prototype to overcome this. In this study, the FAB functions are as navigation and the main action of the prototype. We chose the FAB as a primary action and navigation since its ability to attract user attention and expand and narrow itself. FAB is recommended as navigation if the user needs to access certain parts or application functionality quickly regardless of hierarchy and limited navigation space. To find out the effect of user experience on FAB in this AR-based teaching media. Researchers use UEQ (User Experience Questionnaire). The results of the research show that the prototype using FAB produces three scales at the “above average” level, two scales at the “Good” level, and one scale is at the “excellent” level. Overall, the resulting scale shows pretty good results.},
	booktitle = {2020 3rd {International} {Seminar} on {Research} of {Information} {Technology} and {Intelligent} {Systems} ({ISRITI})},
	author = {Nasri, Muhammad Haris and Hartanto, Rudy and Permanasari, Adhistya Erna and Arfian, Nur},
	month = dec,
	year = {2020},
	keywords = {Education, User experience, Navigation, Prototypes, Mobile applications, User interfaces, Media, Anatomy, AR Media Learning, FAB, UEQ, UI/UX},
	pages = {354--359},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\TRWBRK6W\\9315459.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\FISJG3E6\\Nasri et al. - 2020 - The User Experience effect of Applying Floating Ac.pdf:application/pdf},
}

@inproceedings{chiu_cloud_2014,
	title = {Cloud computing based mobile augmented reality interactive system},
	doi = {10.1109/WCNC.2014.6953084},
	abstract = {Augmented reality (AR) technology is mainly composed of feature extraction, feature points matching and 3D object drawing to impose virtual information onto the real camera. Hand tracking method is designed to realize interactive AR system to further enhance user experience (UX). However, feature extraction, feature points matching, and hand tracking all require high computational cost. To achieve real-time implementation on mobile, we proposed a Mobile Augmented ReAlity Interactive System based on cloud computing (MARAIS). Cloud side is responsible for heavy tasks that need sufficient computational capabilities, and device side performs sensing, detecting and displaying. Device/cloud architecture has been designed to maintain tolerable processing delay with minimum communication overhead. To validate the suitability for real-time interaction, MARAIS is combined with a picture book to realize a digital learning system. Implementation of interactive AR system based on cloud computing eases the requirement of data storage, memory, and computational power at device side.},
	booktitle = {2014 {IEEE} {Wireless} {Communications} and {Networking} {Conference} ({WCNC})},
	author = {Chiu, Pei-Hsuan and Tseng, Po-Hsuan and Feng, Kai-Ten},
	month = apr,
	year = {2014},
	note = {ISSN: 1558-2612},
	keywords = {Cameras, Mobile communication, cloud computing, Cloud computing, Color, Feature extraction, interactive augmented reality (AR) system, Interactive systems, particle filter, Phantoms},
	pages = {3320--3325},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\VDHWZ3GD\\6953084.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\KKX7K3NX\\Chiu et al. - 2014 - Cloud computing based mobile augmented reality int.pdf:application/pdf},
}

@inproceedings{satti_holistic_2019,
	title = {Holistic {User} {eXperience} in {Mobile} {Augmented} {Reality} {Using} {User} {eXperience} {Measurement} {Index}},
	doi = {10.1109/NEXTCOMP.2019.8883528},
	abstract = {User eXperience (UX) evaluation in the field of Mobile Augmented Reality (MAR) is a challenging task, which requires the application of many heterogeneous methods, producing a variety of raw signals and subjective data. This multi-method approach is essential for capturing the holistic UX of any product, service or system. In order to convert this data into information and subsequently knowledge, a comprehensive and scalable system is required which can not only quantify the individual UX metrics but also produce a concise result, which is interpretable by anyone. We call this result, the User Experience Measurement Index, and in this paper we present the results of adopting the mixed method UX evaluation approach for evaluating a prototype MAR application using various methods and sensors, applied before, during, and after its usage. Additionally, we present the methodology and results for calculating the UXMI.},
	booktitle = {2019 {Conference} on {Next} {Generation} {Computing} {Applications} ({NextComp})},
	author = {Satti, Fahad Ahmed and Hussain, Jamil and Muhammad Bilal, Hafiz Syed and Khan, Wajahat Ali and Khattak, Asad Masood and Yeon, Ju Eun and Lee, Sungyoung},
	month = sep,
	year = {2019},
	keywords = {User experience, Emotional responses, Instruments, Measurement, Mixed Method, Mobile Augmented Reality, Physiology, Sensors, Task analysis, UX, UXMI},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\TMAUDYJI\\8883528.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\8F4SDD7H\\Satti et al. - 2019 - Holistic User eXperience in Mobile Augmented Reali.pdf:application/pdf},
}

@article{chiu_interactive_2018,
	title = {Interactive {Mobile} {Augmented} {Reality} {System} for {Image} and {Hand} {Motion} {Tracking}},
	volume = {67},
	issn = {1939-9359},
	doi = {10.1109/TVT.2018.2864893},
	abstract = {In recent years, augmented reality (AR) is considered a promising technology that combines virtual information such as videos, images, and three-dimensional objects with a real camera view in mobile platforms. Interactive AR further provides human-computer interaction to allow the user to interact with virtual objects on the mobile display. In this paper, we proposed a cloud-based mobile augmented reality interactive system (MARIS), which includes MARIS-I for image target tracking and MARIS-H for hand motion tracking. MARIS-I estimates the position of the image target by adopting a feature-based mean-shift algorithm, which is feasible for real-time applications with its small region feature detection. MARIS-H provides two tracking modes for fingertip and back of hand tracking to enhance user experiences (UX) for interaction. Either the center position for the back of hand or fingertip is first estimated by particle filtering technique, which calculates the weighting of each particle according to hand or fingertip model. Afterward, the contour of the fingertip is estimated by level-set-based contour evolution in the fingertip tracking mode. Furthermore, we implement a device/cloud architecture for the proposed MARIS to decrease memory requirement and computational complexity on the device side. Experimental results show that MARIS including MARIS-I and MARIS-H can outperform other existing methods for image and hand motion tracking, respectively. The proposed MARIS is demonstrated in a picture book to provide fruitful interactive UX for digital learning systems.},
	number = {10},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Chiu, Pei-Hsuan and Tseng, Po-Hsuan and Feng, Kai-Ten},
	month = oct,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Vehicular Technology},
	keywords = {Augmented reality, Mobile handsets, Cameras, Real-time systems, Feature extraction, motion tracking, particle filtering, Target tracking},
	pages = {9995--10009},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\WZATLBSP\\8432093.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\YGAUNANU\\Chiu et al. - 2018 - Interactive Mobile Augmented Reality System for Im.pdf:application/pdf},
}

@inproceedings{dabor_design_2019,
	title = {Design {Guidelines} for {Augmented} {Reality} {User} {Interface}: {A} {Case} {Study} of {Simultaneous} {Interpretation}},
	shorttitle = {Design {Guidelines} for {Augmented} {Reality} {User} {Interface}},
	doi = {10.1109/CEEC47804.2019.8974331},
	abstract = {Cognitive load theory (CLT) is concerned with the design of interfaces that allow users maximize their working memory when problem solving. This includes eliminating any subjective mental load that may be imposed by the instruction interface. Augmented reality (AR) is fast gaining application in areas of education, military, business and medicine with new AR applications developed daily. Despite its wide application little has been done in the area of design guidelines for AR user interface and the evaluation of its effect. This is necessary so as to ensure that users are not burdened by the format and amount of information presented in the augmented view. This work - in - progress aims to propose a framework for designing AR user interfaces that imposes reduced subjective mental workload on users. Particular attention is given to highly cognitive tasks such as simultaneous interpretation. This research work will concentrate on presenting the novel guidelines for the user interface design.},
	booktitle = {2019 11th {Computer} {Science} and {Electronic} {Engineering} ({CEEC})},
	author = {Dabor, Oluwadunsin and Longford, Edward and Walker, Stuart},
	month = sep,
	year = {2019},
	keywords = {Augmented Reality, Cognitive load theory, User Interface},
	pages = {164--166},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\F8XK2S58\\8974331.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\G829U4LH\\Dabor et al. - 2019 - Design Guidelines for Augmented Reality User Inter.pdf:application/pdf},
}

@article{irshad_design_2020,
	title = {Design and {Implementation} of {User} {Experience} {Model} for {Augmented} {Reality} {Systems}},
	abstract = {Mobile Augmented Reality (MAR) is a system that combines digital and virtual content for users so users are not fully immersed in the virtual world but can benefit from immersive experiences while still being in the real world. However, the end-user may experience various design challenges while using such immersive technologies. To deliver positive User Experience (UX), researchers need to understand the design factors, end-user challenges, and enhance the overall immersive UX for MAR. This research follows the design science approach to present a UX model for MAR, which encapsulate components and design factors that can aid in positive UX. We developed a MAR system to verify and validate the UX model by evaluating and benchmarking it. The experimental results show excellent system novelty, good attractiveness and perspicuity compared to the benchmark. The findings suggest that the efficiency, dependability, and stimulation of MAR can be improved to enhance the UX further. This study’s research knowledge can be utilized to improve the immersive design and engineering of MAR services based on understanding the practical aspirations of potential end-users.},
	language = {en},
	author = {Irshad, Shafaq and Rambli, Dayang Rohaya Awang and Sulaiman, Suziah},
	year = {2020},
	pages = {10},
	file = {Irshad et al. - 2020 - Design and Implementation of User Experience Model.pdf:C\:\\Users\\croch\\Zotero\\storage\\EDJBJICR\\Irshad et al. - 2020 - Design and Implementation of User Experience Model.pdf:application/pdf},
}

@inproceedings{irshad_preliminary_2015,
	title = {Preliminary user experience framework for designing mobile augmented reality technologies},
	doi = {10.1109/IDM.2015.7547833},
	abstract = {User eXperience (UX) is identified as the characteristics of the designed system, the result of user's internal state, and the context within which the interaction between the system and user occurs. UX is becoming increasingly diverse and well established field especially in the context of its usage. Nevertheless, this field of research lack conceptual and practical frameworks to be followed while designing for emerging technologies like Augmented Reality (AR). This paper presents an early framework for designing and evaluating the UX of Mobile Augmented Reality (MAR) applications. The credibility of this work-in-progress UX frame-work is supported by recent validated research on UX and MAR studies.},
	booktitle = {2015 4th {International} {Conference} on {Interactive} {Digital} {Media} ({ICIDM})},
	author = {Irshad, Shafaq and Rambli, Dayang Rohaya Awang},
	month = dec,
	year = {2015},
	keywords = {Augmented reality, Context, Mobile communication, Usability, Design, Evaluation, Framework, Human computer interaction, Mars, Mobile Augmented Reality (MAR), User eXperience (UX), User interface (UI)},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\H24M6ZF4\\7547833.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\ACNH2GA9\\Irshad and Rambli - 2015 - Preliminary user experience framework for designin.pdf:application/pdf},
}

@inproceedings{cruz_object_2013,
	title = {Object recognition and detection by shape and color pattern recognition utilizing {Artificial} {Neural} {Networks}},
	doi = {10.1109/ICoICT.2013.6574562},
	abstract = {A robust and accurate object recognition tool is presented in this paper. The paper introduced the use of Artificial Neural Networks in evaluating a frame shot of the target image. The system utilizes three major steps in object recognition, namely image processing, ANN processing and interpretation. In image processing stage a frame shot or an image go through a process of extracting numerical values of object's shape and object's color. These values are then fed to the Artificial Neural Network stage, wherein the recognition of the object is done. Since the output of the ANN stage is in numerical form the third process is indispensable for human understanding. This stage simply converts a given value to its equivalent linguistic term. All three components are integrated in an interface for ease of use. Upon the conclusion of the system's development, experimentation and testing procedures are initiated. The study proved that the optimum lighting condition opted for the system is at 674 lumens with an accuracy of 99.99996072\%. Another finding that the paper presented is that the optimum distance for recognition is at 40cm with an accuracy of 99.99996072\%. Lastly the system contains a very high tolerance in the variations in the objects position or orientation, with the optimum accuracy at upward position with 99.99940181\% accuracy rate.},
	booktitle = {2013 {International} {Conference} of {Information} and {Communication} {Technology} ({ICoICT})},
	author = {Cruz, Jerome Paul N. and Dimaala, Ma. Lourdes and Francisco, Laurene Gaile L. and Franco, Erica Joanna S. and Bandala, Argel A. and Dadios, Elmer P.},
	month = mar,
	year = {2013},
	keywords = {Object recognition, (ANN, pattern recognition,object detection), Accuracy, artificial neural networks, Artificial neural networks, Equations, Image color analysis, Mathematical model, Neurons, object recognition, vision system},
	pages = {140--144},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\XWLP5X6Y\\6574562.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\4RXZKWQ9\\Cruz et al. - 2013 - Object recognition and detection by shape and colo.pdf:application/pdf},
}

@article{pereira_object_nodate,
	title = {Object {Recognition} {In} {Augmented} {Reality}},
	language = {en},
	author = {Pereira, Chester},
	pages = {48},
	file = {Pereira - Object Recognition In Augmented Reality.pdf:C\:\\Users\\croch\\Zotero\\storage\\ATCTUIE3\\Pereira - Object Recognition In Augmented Reality.pdf:application/pdf},
}

@inproceedings{tang_object_2016,
	title = {Object {Recognition} via {Classifier} {Interaction} with {Multiple} {Features}},
	volume = {02},
	doi = {10.1109/IHMSC.2016.205},
	abstract = {In this paper, a robust object recognition method via classifier interaction with multiple features is proposed to recognize an object in dynamic conditions that include illumination changes, pose variations, and occlusions. To account for the better recognition effect, multiple classifiers with different features are utilized, and each of which will get satisfactory result by classifier selection and interacting with each other. To integrate multiple classifiers for accurate object recognition, we propose two solutions: (1) the classifier selection, and (2) classifier interaction modules within a Bayesian framework. The experimental results demonstrate that our proposed method is robust and highly active in the field of object recognition.},
	booktitle = {2016 8th {International} {Conference} on {Intelligent} {Human}-{Machine} {Systems} and {Cybernetics} ({IHMSC})},
	author = {Tang, Jie and Wen, Gongjian},
	month = aug,
	year = {2016},
	keywords = {Object recognition, Feature extraction, Bayes methods, Bayesian framework, Classification algorithms, Classifier Interaction, Lighting, Multiple Features, Robustness},
	pages = {337--340},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\6RY4Z3WX\\7783851.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\3CWKWK92\\Tang and Wen - 2016 - Object Recognition via Classifier Interaction with.pdf:application/pdf},
}

@inproceedings{ikizler-cinbis_object_2010,
	title = {Object {Recognition} and {Localization} {Via} {Spatial} {Instance} {Embedding}},
	doi = {10.1109/ICPR.2010.119},
	abstract = {We propose an approach for improving object recognition and localization using spatial kernels together with instance embedding. Our approach treats each image as a bag of instances (image features) within a multiple instance learning framework, where the relative locations of the instances are considered as well as the appearance similarity of the localized image features. The introduced spatial kernel augments the recognition power of the instance embedding in an intuitive and effective way, providing increased localization performance. We test our approach over two object datasets and present promising results.},
	booktitle = {2010 20th {International} {Conference} on {Pattern} {Recognition}},
	author = {Ikizler-Cinbis, Nazli and Sclaroff, Stan},
	month = aug,
	year = {2010},
	note = {ISSN: 1051-4651},
	keywords = {Object recognition, Feature extraction, object recognition, Cognition, Computer vision, Dictionaries, Kernel, multiple instance learning, object localization, Support vector machines},
	pages = {452--455},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\IS3BWB9N\\5597413.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\FSR9MB3Y\\Ikizler-Cinbis and Sclaroff - 2010 - Object Recognition and Localization Via Spatial In.pdf:application/pdf},
}

@inproceedings{kim_edge_2021,
	title = {Edge {Computing} {System} applying {Integrated} {Object} {Recognition} based on {Deep} {Learning}},
	doi = {10.23919/ICACT51234.2021.9370761},
	abstract = {With the development of personal broadcasting such as YouTube, the demand for editing the video he filmed himself is steadily increasing. Traditional media video editing solutions help edit the results of the filming. However, there is a problem that requires a lot of editing time, as people usually edit videos that are from tens to hundreds of times longer than the final result of a personal broadcasting after filming. To overcome this problem, this paper automatically classifies images with specific scenes in the whole media image editing process, and secondly proposes automatic media editing solution technology in which people intervene. In particular, personal broadcasting focuses on the use of images that include characters, specific objects, and cue sign gestures among the entire. While the existing deep learning techniques such as faces, objects and gestures are advanced, integrated recognition technologies that simultaneously deal with special requirements for editing videos are still in the early stages of research. In this paper, the automatic composite recognition technology for editing video based on deep learning is proposed. The proposed technology was implemented with python and tensorflow software based on edge computing equipment. Using actual youtube videos, it took 0.1 second to process five-person recognition, 63-food recognition, or cue sign recognition using clapping or V poses at the same time. The recognized results are divided into timestamps of the entire movie, recognition results, and locations of objects on the screen, and are output to the json file. In addition, this solution was developed on an edge computing in order to increase real-time reliability. We expect to provide automatic video editing based on perceived json results as well as shorter editing times based on this implementation.},
	booktitle = {2021 23rd {International} {Conference} on {Advanced} {Communication} {Technology} ({ICACT})},
	author = {Kim, Kwihoon and Oh, Sewon},
	month = feb,
	year = {2021},
	note = {ISSN: 1738-9445},
	keywords = {Media, Deep learning, Object recognition, Real-time systems, Streaming media, Automatic media editor, Context recognition, Edge computing, Face recognition},
	pages = {415--419},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\GZZ7SHAP\\9370761.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\NTWAYSAB\\Kim and Oh - 2021 - Edge Computing System applying Integrated Object R.pdf:application/pdf},
}

@inproceedings{jha_e-commerce_2021,
	title = {E-{Commerce} {Product} {Image} {Classification} using {Transfer} {Learning}},
	doi = {10.1109/ICCMC51019.2021.9418371},
	abstract = {E-commerce is the platform where it provisions the online businesses for selling and buying. Organizing and searching for products is a cumbersome process for service providers and customers. The considerable time are getting wasted in organizing and labeling the products. The most commonly used algorithm for image classification is the convolutional neural network (CNN). Training a huge dataset consumes a lot of computational resources and time. Image search is good when we don't have many details about the product. We have proposed a transfer learning approach based on visual geometry group-19 (VGG-19) and Inception V3 to overcome the issues related to classification, product identification, product suggestion, and image-based search. We have taken a Kaggle dataset of 70000, 28x28 labeled fashion images. The dataset is split into 85\% training and 15\% validation. The training and validation accuracy of the proposed transfer learning approach is better whereas the loss is lower as compared to CNN based approach.},
	booktitle = {2021 5th {International} {Conference} on {Computing} {Methodologies} and {Communication} ({ICCMC})},
	author = {Jha, Bineet Kumar and G, Sivasankari G. and R, Venugopal K.},
	month = apr,
	year = {2021},
	keywords = {Computational modeling, Visualization, Labeling, Training, autoencoders, CNN, computer vision, e-commerce, Geometry, image classification, machine learning, ResNet, Scalability, transfer learning, Transfer learning, VGG},
	pages = {904--912},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\YBU2JF4H\\9418371.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\PS7CPEKL\\Jha et al. - 2021 - E-Commerce Product Image Classification using Tran.pdf:application/pdf},
}

@inproceedings{novozamsky_automated_2020,
	title = {Automated {Object} {Labeling} {For} {Cnn}-{Based} {Image} {Segmentation}},
	doi = {10.1109/ICIP40778.2020.9191320},
	abstract = {Deep learning-based methods for classification and segmentation require large training sets. Generating training data is often a tedious and expensive task. In industrial applications, such as automated visual inspection of products in an assemble line, objects for classification are well defined yet labeled data are difficult to obtain. To alleviate the problem of manual labeling, we propose to train a convolutional neural network with an automatically generated training set using a naive classifier with handcrafted features. We show that when the naive classifier has high precision then the trained network has both high precision and recall despite the low recall of the naive classifier. We demonstrate the proposed methodology on real scenario of detecting a car coolant tank. However, the proposed methodology facilitates collection of train data for a wider type of CNN based methods such as near-duplicate image detection or segmenting tampered areas of images.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Novozámský, A. and Vít, D. and Šroubek, F. and Franc, J. and Krbálek, M. and Bílkova, Z. and Zitová, B.},
	month = oct,
	year = {2020},
	note = {ISSN: 2381-8549},
	keywords = {Labeling, Training, Task analysis, CNN, automated object labeling, Automobiles, Coolants, image segmentation, Image segmentation, SURF, Training data, U-net},
	pages = {2036--2040},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\IEIZT96S\\9191320.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\P8EGCM5H\\Novozámský et al. - 2020 - Automated Object Labeling For Cnn-Based Image Segm.pdf:application/pdf},
}

@inproceedings{zhang_distributed_2021,
	title = {Distributed {Client}-{Server} {Optimization} for {SLAM} with {Limited} {On}-{Device} {Resources}},
	doi = {10.1109/ICRA48506.2021.9561638},
	abstract = {Simultaneous localization and mapping (SLAM) is a crucial functionality for exploration robots and virtual/augmented reality (VR/AR) devices. However, some of such devices with limited resources cannot afford the computational or memory cost to run full SLAM algorithms. We propose a general client-server SLAM optimization framework that achieves accurate real-time state estimation on the device with low requirements of on-board resources. The resource-limited device (the client) only works on a small part of the map, and the rest of the map is processed by the server. By sending the summarized information of the rest of map to the client, the on-device state estimation is more accurate. Further improvement of accuracy is achieved in the presence of on-device early loop closures, which enables reloading useful variables from the server to the client. Experimental results from both synthetic and real-world datasets demonstrate that the proposed optimization framework achieves accurate estimation in real-time with limited computation and memory budget of the device.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Zhang, Yetong and Hsiao, Ming and Zhao, Yipu and Dong, Jing and Engel, Jakob J.},
	month = may,
	year = {2021},
	note = {ISSN: 2577-087X},
	keywords = {Real-time systems, Performance evaluation, Refining, Servers, Simultaneous localization and mapping, Systematics, Uncertainty},
	pages = {5336--5342},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\H2AY6P4G\\9561638.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\LL9RNYS3\\Zhang et al. - 2021 - Distributed Client-Server Optimization for SLAM wi.pdf:application/pdf},
}

@inproceedings{le_automatic_2020,
	title = {Automatic {Data} {Generation} for {Deep} {Learning} {Model} {Training} of {Image} {Classification} used for {Augmented} {Reality} on {Pre}-school {Books}},
	doi = {10.1109/MAPR49794.2020.9237760},
	abstract = {Nowadays, Augmented Reality (AR) has rightfully been taking as one of the leading position. Still, there are many different AR markers with different encryption and decryption methods which provide the users with an excellent capability to augment computer graphics generated virtual information onto real-world objects (e.g. text-book pictures or diagrams). However, the users need to choose which marker provider that matches their needs and create suitable markers based on the chosen provider's requirements. “Is it worth to re-print the entire existing books in-order to add AR functions?”. In this paper, we describe a new architecture to set up and present AR experiences by applying the benefit of deep learning (DL), the power of smart devices, and the flexibility of the Client-Server Architecture of the Internet. To set up, photos of pages in a textbook (but not limited to all pages) are uploaded to our server. For each page, the server will automatically generate different 3D views (thousands with different light conditions and perspectives) of the pages to form a sufficiently large enough dataset. They are then trained with a chosen convolutional neural network such as Alexnet, GoogleNet, VGG, GoogLeNet, or ResNet. The obtained model is then stored and can be loaded back to the client to serve as a classification process on a web browser using TensorFlow.JS, to recognise pages of the book. TensorFlow.JS is capable of running on smart devices with their built-in cameras; the recognised page will be used to specify which 3D graphics is displaying on top the page. This novel AR marker generating method is not only capable of keeping the original images of the books but also believed to achieve a higher detection accuracy. Thus, it is a promising, low-cost AR approach to be used in many areas, including education and training.},
	booktitle = {2020 {International} {Conference} on {Multimedia} {Analysis} and {Pattern} {Recognition} ({MAPR})},
	author = {Le, Huy and Nguyen, Minh and Nguyen, Quan and Nguyen, Hoa and Yan, Wei Qi},
	month = oct,
	year = {2020},
	keywords = {Augmented reality, Augmented Reality, Education, Computer architecture, Three-dimensional displays, Deep learning, Smart devices, Training, Deep Learning, Servers, Convolutional Neural Network, Machine Learning},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\NBL9PUCS\\9237760.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\DTG4KK53\\Le et al. - 2020 - Automatic Data Generation for Deep Learning Model .pdf:application/pdf},
}

@inproceedings{gammeter_server-side_2010,
	title = {Server-side object recognition and client-side object tracking for mobile augmented reality},
	doi = {10.1109/CVPRW.2010.5543248},
	abstract = {In this paper we present a system for mobile augmented reality (AR) based on visual recognition. We split the tasks of recognizing an object and tracking it on the user's screen into a server-side and a client-side task, respectively. The capabilities of this hybrid client-server approach are demonstrated with a prototype application on the Android platform, which is able to augment both stationary (landmarks) and non stationary (media covers) objects. The database on the server side consists of hundreds of thousands of landmarks, which is crawled using a state of the art mining method for community photo collections. In addition to the landmark images, we also integrate a database of media covers with millions of items. Retrieval from these databases is done using vocabularies of local visual features. In order to fulfill the real-time constraints for AR applications, we introduce a method to speed-up geometric verification of feature matches. The client-side tracking of recognized objects builds on a multi-modal combination of visual features and sensor measurements. Here, we also introduce a motion estimation method, which is more efficient and precise than similar approaches. To the best of our knowledge this is the first system, which demonstrates a complete pipeline for augmented reality on mobile devices with visual object recognition scaled to millions of objects combined with real-time object tracking.},
	booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} - {Workshops}},
	author = {Gammeter, Stephan and Gassmann, Alexander and Bossard, Lukas and Quack, Till and Van Gool, Luc},
	month = jun,
	year = {2010},
	note = {ISSN: 2160-7516},
	keywords = {Augmented reality, Prototypes, Object recognition, Image databases, Information retrieval, Multimodal sensors, Sensor phenomena and characterization, Spatial databases, Visual databases, Vocabulary},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\7KW9F49J\\5543248.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\3FG8WWRY\\Gammeter et al. - 2010 - Server-side object recognition and client-side obj.pdf:application/pdf},
}

@inproceedings{ha_real-time_2011,
	title = {Real-time scalable recognition and tracking based on the server-client model for mobile {Augmented} {Reality}},
	doi = {10.1109/ISVRI.2011.5759649},
	abstract = {Recent mobile device and vision technology advances have enabled mobile Augmented Reality (AR) to be serviced in real-time using natural features. However, in viewing augmented reality while moving about, the user is always encountering new and diverse target objects in different locations. Whether the AR system is scalable or not to the number of target objects is an important issue for future mobile AR services. But this scalability has been far limited due to the small capacity of internal storage and memory of the mobile devices. In this paper, a new framework is proposed that achieves scalability for mobile augmented reality. The scalability is achieved by using a bag of visual words based recognition module on the server side with connected through conventional Wi-Fi. On the client side, the mobile phone tracks and augments based on natural features in real-time. In the experiment, it takes 0.2 seconds for the cold start of an AR service initiated on a 10k object database with recognition accuracy 95\%, which is acceptable for a real-world mobile AR application.},
	booktitle = {2011 {IEEE} {International} {Symposium} on {VR} {Innovation}},
	author = {Ha, Jaewon and Cho, Kyusung and Rojas, Francisco A. and Yang, Hyun S.},
	month = mar,
	year = {2011},
	keywords = {Augmented Reality, Mobile handsets, Mobile communication, Visualization, Mobile Augmented Reality, Target tracking, Servers, Databases, Mobile Phones, Pixel, Scalable Recognition, Visual Tracking},
	pages = {267--272},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\7L844FS8\\5759649.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\P6AMNJ3C\\Ha et al. - 2011 - Real-time scalable recognition and tracking based .pdf:application/pdf},
}

@inproceedings{cao_5g_2021,
	title = {{5G} {Edge} {Computing} {Enhanced} {Mobile} {Augmented} {Reality}},
	doi = {10.1109/PerComWorkshops51409.2021.9431024},
	abstract = {Physical world enhancements through virtually drawn annotations on mobile devices are a core component of mobile augmented reality (MAR) experiences. However, resource intensive computer vision tasks typically limit the full deployment of MAR pipelines on-device due to a lack of required computation resources. As an alternative, a distributed scheme between client devices and edge servers enables offloading computation intensive tasks to powerful machines. This introduces challenges, such as maintaining low communication latency and high bandwidth channels between client and edge server. Current LTE and WiFi infrastructure do not fulfil such requirements. 5G networks are an ideal candidate to provide seamless MAR experiences. This research investigates the enhancement of MAR with both 5G and edge computing and aims to address two particular challenges: 1) the creation of a new 5G-based edge computing infrastructure to support reliable MAR, and 2) investigating which particular transport protocols allow for optimised quality of experience (QoE) for MAR applications within 5G infrastructure.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Pervasive} {Computing} and {Communications} {Workshops} and other {Affiliated} {Events} ({PerCom} {Workshops})},
	author = {Cao, Jacky and Su, Xiang},
	month = mar,
	year = {2021},
	keywords = {mobile augmented reality, Conferences, Reliability, Task analysis, Servers, 5g, 5G mobile communication, edge computing, Quality of experience, Transport protocols},
	pages = {416--417},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\AX5KNEY5\\9431024.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\BP52GM7J\\Cao and Su - 2021 - 5G Edge Computing Enhanced Mobile Augmented Realit.pdf:application/pdf},
}

@inproceedings{bai_poster_2013,
	title = {Poster: {Markerless} fingertip-based {3D} interaction for handheld augmented reality in a small workspace},
	shorttitle = {Poster},
	doi = {10.1109/3DUI.2013.6550212},
	abstract = {Compared with traditional screen-touch input, natural gesture-based interaction approaches could offer a more intuitive user experience in handheld Augmented Reality (AR) applications. However, most gesture interaction techniques for handheld AR only use two degrees of freedom without the third depth dimension, while AR virtual objects are overlaid on a view of a three dimensional space. In this paper, we investigate a markerless fingertip-based 3D interaction method within a client-server framework in a small workspace. Our solution includes seven major components: (1) fingertip detection (2) fingertip depth acquisition (3) marker tracking (4) coordinate transformation (5) data communication (6) gesture interaction (7) graphic rendering. We describe the process of each step in details and present performance results of our prototype.},
	booktitle = {2013 {IEEE} {Symposium} on {3D} {User} {Interfaces} ({3DUI})},
	author = {Bai, Huidong and Gao, Lei and Billinghurst, Mark},
	month = mar,
	year = {2013},
	keywords = {Augmented reality, Mobile handsets, Cameras, Mobile communication, Three-dimensional displays, Target tracking, Servers, H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities},
	pages = {129--130},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\WM3J8MSR\\6550212.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\S2BLPZM9\\Bai et al. - 2013 - Poster Markerless fingertip-based 3D interaction .pdf:application/pdf},
}

@inproceedings{kao_cloud-based_2013,
	title = {A {Cloud}-{Based} {Framework} to {Enhance} {Augmented} {Reality}},
	doi = {10.1109/CISIS.2013.22},
	abstract = {We propose a cloud-based framework for AR applications. The framework is combined of state-of-the-art Virtualization Desktop Infrastructure (VDI) of Personal Cloud Computer (PC2) and parallel computing technique of MapReduce. We design a sophisticated client-server architecture to enhance performance of multi-user Augmented Reality (AR) application. Computing load balance is the design concern between client devices and application servers. A multi-user AR game is used as case study running on parallel Virtual Machines (Vs.). We also explore the concurrent AR mechanism on cooperation VMs. Finally, we conclude our proposed work and point future work.},
	booktitle = {2013 {Seventh} {International} {Conference} on {Complex}, {Intelligent}, and {Software} {Intensive} {Systems}},
	author = {Kao, Chung-Ting and Jan, Kai-Yuan and Chen, Rick C.S.},
	month = jul,
	year = {2013},
	keywords = {Augmented reality, augmented reality, Cameras, Computer architecture, Servers, client-server, cloud, Decoding, Games, rendering, Rendering (computer graphics), virtual desktop},
	pages = {78--82},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\DCNI5S84\\6603870.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\3LPKZW4C\\Kao et al. - 2013 - A Cloud-Based Framework to Enhance Augmented Reali.pdf:application/pdf},
}

@article{qiao_web_2019,
	title = {Web {AR}: {A} {Promising} {Future} for {Mobile} {Augmented} {Reality}—{State} of the {Art}, {Challenges}, and {Insights}},
	volume = {107},
	issn = {1558-2256},
	shorttitle = {Web {AR}},
	doi = {10.1109/JPROC.2019.2895105},
	abstract = {Mobile augmented reality (Mobile AR) is gaining increasing attention from both academia and industry. Hardware-based Mobile AR and App-based Mobile AR are the two dominant platforms for Mobile AR applications. However, hardware-based Mobile AR implementation is known to be costly and lacks flexibility, while the App-based one requires additional downloading and installation in advance and is inconvenient for cross-platform deployment. In comparison, Web-based AR (Web AR) implementation can provide a pervasive Mobile AR experience to users thanks to the many successful deployments of the Web as a lightweight and cross-platform service provisioning platform. Furthermore, the emergence of 5G mobile communication networks has the potential to enhance the communication efficiency of Mobile AR dense computing in the Web-based approach. We conjecture that Web AR will deliver an innovative technology to enrich our ways of interacting with the physical (and cyber) world around us. This paper reviews the state-of-the-art technology and existing implementations of Mobile AR, as well as enabling technologies and challenges when AR meets the Web. Furthermore, we elaborate on the different potential Web AR provisioning approaches, especially the adaptive and scalable collaborative distributed solution which adopts the osmotic computing paradigm to provide Web AR services. We conclude this paper with the discussions of open challenges and research directions under current 3G/4G networks and the future 5G networks. We hope that this paper will help researchers and developers to gain a better understanding of the state of the research and development in Web AR and at the same time stimulate more research interest and effort on delivering life-enriching Web AR experiences to the fast-growing mobile and wireless business and consumer industry of the 21st century.},
	number = {4},
	journal = {Proceedings of the IEEE},
	author = {Qiao, Xiuquan and Ren, Pei and Dustdar, Schahram and Liu, Ling and Ma, Huadong and Chen, Junliang},
	month = apr,
	year = {2019},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Augmented reality, Mobile handsets, cloud computing, Cloud computing, Performance evaluation, 5G mobile communication, edge computing, 5G, augmented reality (AR), Communication networks, mixed reality, mobile augmented reality (Mobile AR), osmotic computing, Research and development, virtual reality (VR), Web-based augmented reality (Web AR)},
	pages = {651--666},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\LP3NKBD8\\8643424.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\G5W74IRB\\Qiao et al. - 2019 - Web AR A Promising Future for Mobile Augmented Re.pdf:application/pdf},
}

@article{rong_dynamic_2012,
	title = {Dynamic programming based algorithms for the discounted \{0–1\} knapsack problem},
	volume = {218},
	issn = {0096-3003},
	url = {https://www.sciencedirect.com/science/article/pii/S0096300311015554},
	doi = {10.1016/j.amc.2011.12.068},
	abstract = {The discounted \{0–1\} knapsack problem (DKP) is an extension of the classical \{0–1\} knapsack problem (KP) that consists of selecting a set of item groups where each group includes three items and at most one of the three items can be selected. The DKP is more challenging than the KP because four choices of items in an item group diversify the selection of the items. Consequently, it is not possible to solve the DKP based on a classical definition of a core consisting of a small number of relevant variables. This paper partitions the DKP into several easier sub-problems to achieve problem reductions by imitating the core concept of the KP to derive an alternative core for the DKP. Numerical experiments with DP-based algorithms are conducted to evaluate the effectiveness of the problem partition by solving the partitioned problem and the original problem based on different types of DKP instances.},
	language = {en},
	number = {12},
	urldate = {2022-05-04},
	journal = {Applied Mathematics and Computation},
	author = {Rong, Aiying and Figueira, José Rui and Klamroth, Kathrin},
	month = feb,
	year = {2012},
	keywords = {Core concept, Discounted knapsack problem, Dynamic programming, Problem partition},
	pages = {6921--6933},
	file = {ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\QBXAMX8L\\S0096300311015554.html:text/html},
}

@misc{yichao_four_2019,
	title = {Four kinds of {D}\{0-1\}{KP} instances},
	abstract = {Four kinds of D\{0-1\}KP instances},
	author = {Yichao, He},
	month = sep,
	year = {2019},
}

@article{feng_binary_2018,
	title = {Binary {Moth} {Search} {Algorithm} for {Discounted} 0-1 {Knapsack} {Problem}},
	volume = {6},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2018.2809445},
	abstract = {The discounted 0-1 knapsack problem (DKP) extends the classical 0-1 knapsack problem (0-1 KP) in which a set of item groups is included and each group consists of three items, whereas at most one of the three items can be packed into the knapsack. Therefore, the DKP is more complicated and computationally difficult than 0-1 KP. The DKP has been found many applications in real economic problems and other areas. In this paper, the influence of Lévy flights operator and fly straightly operator in the moth search (MS) algorithm is verified. Nine types of new mutation operator based on the global harmony search are specially devised to replace Lévy flights operator. Then, nine novel MS-based algorithms for DKP are proposed (denoted by MS1-MS9). Extensive experiments on three sets of 30 DKP instances demonstrate the remarkable performance of the proposed nine new MS-based approaches. In particular, it discovers that MS1-MS3 show better comprehensive performance among 10 algorithms. A variety of analyses indicate the important contribution of the individual of memory consideration in MS1-MS9.},
	journal = {IEEE Access},
	author = {Feng, Yan-Hong and Wang, Gai-Ge},
	year = {2018},
	note = {Conference Name: IEEE Access},
	keywords = {Discounted 0-1 knapsack problem, harmony search, moth search, Optimization, Particle swarm optimization, Search problems, Silicon, Sociology, Standards, Statistics, swarm intelligence},
	pages = {10708--10719},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\EMQLL7EN\\8302509.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\7DKQ3CY3\\Feng and Wang - 2018 - Binary Moth Search Algorithm for Discounted 0-1 Kn.pdf:application/pdf},
}

@article{wang_monarch_2019,
	title = {Monarch butterfly optimization},
	volume = {31},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-015-1923-y},
	doi = {10.1007/s00521-015-1923-y},
	abstract = {In nature, the eastern North American monarch population is known for its southward migration during the late summer/autumn from the northern USA and southern Canada to Mexico, covering thousands of miles. By simplifying and idealizing the migration of monarch butterflies, a new kind of nature-inspired metaheuristic algorithm, called monarch butterfly optimization (MBO), a first of its kind, is proposed in this paper. In MBO, all the monarch butterfly individuals are located in two distinct lands, viz. southern Canada and the northern USA (Land 1) and Mexico (Land 2). Accordingly, the positions of the monarch butterflies are updated in two ways. Firstly, the offsprings are generated (position updating) by migration operator, which can be adjusted by the migration ratio. It is followed by tuning the positions for other butterflies by means of butterfly adjusting operator. In order to keep the population unchanged and minimize fitness evaluations, the sum of the newly generated butterflies in these two ways remains equal to the original population. In order to demonstrate the superior performance of the MBO algorithm, a comparative study with five other metaheuristic algorithms through thirty-eight benchmark problems is carried out. The results clearly exhibit the capability of the MBO method toward finding the enhanced function values on most of the benchmark problems with respect to the other five algorithms. Note that the source codes of the proposed MBO algorithm are publicly available at GitHub (https://github.com/ggw0122/Monarch-Butterfly-Optimization, C++/MATLAB) and MATLAB Central (http://www.mathworks.com/matlabcentral/fileexchange/50828-monarch-butterfly-optimization, MATLAB).},
	language = {en},
	number = {7},
	urldate = {2022-05-02},
	journal = {Neural Comput \& Applic},
	author = {Wang, Gai-Ge and Deb, Suash and Cui, Zhihua},
	month = jul,
	year = {2019},
	keywords = {Benchmark problems, Butterfly adjusting operator, Evolutionary computation, Migration, Monarch butterfly optimization},
	pages = {1995--2014},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\NVGM9QHZ\\Wang et al. - 2019 - Monarch butterfly optimization.pdf:application/pdf},
}

@article{dang_binary_2022,
	title = {Binary salp swarm algorithm for discounted \{0-1\} knapsack problem},
	volume = {17},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0266537},
	doi = {10.1371/journal.pone.0266537},
	abstract = {While the classical knapsack problem has been the object to be solved by optimization algorithm proposals for many years, another version of this problem, discounted \{0-1\} knapsack problem, is gaining a lot of attention recently. The original knapsack problem requires selecting specific items from an item set to maximize the total benefit while ensuring that the total weight does not exceed the knapsack capacity. Meanwhile, discounted \{0-1\} knapsack problem has more stringent requirements in which items are divided into groups, and only up to one item from a particular group can be selected. This constraint, which does not exist in the original knapsack problem, makes discounted \{0-1\} knapsack problem even more challenging. In this paper, we propose a new algorithm based on salp swarm algorithm in the form of four different variants to resolve the discounted \{0-1\} knapsack problem. In addition, we also make use of an effective data modeling mechanism and a greedy repair operator that helps overcome local optima when finding the global optimal solution. Experimental and statistical results show that our algorithm is superior to currently available algorithms in terms of solution quality, convergence, and other statistical criteria.},
	language = {en},
	number = {4},
	urldate = {2022-05-02},
	journal = {PLOS ONE},
	author = {Dang, Binh Thanh and Truong, Tung Khac},
	month = apr,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Algorithms, Optimization, Animal migration, Evolutionary algorithms, Evolutionary genetics, Genetic algorithms, Mathematical models, Moths and butterflies},
	pages = {e0266537},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\RECXCYQG\\Dang and Truong - 2022 - Binary salp swarm algorithm for discounted 0-1 k.pdf:application/pdf;Snapshot:C\:\\Users\\croch\\Zotero\\storage\\66MADVTJ\\article.html:text/html},
}

@article{feng_multi-strategy_2018,
	title = {Multi-strategy monarch butterfly optimization algorithm for discounted \{0-1\} knapsack problem},
	volume = {30},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-017-2903-1},
	doi = {10.1007/s00521-017-2903-1},
	abstract = {As an expanded classical 0-1 knapsack problem (0-1 KP), the discounted \{0-1\} knapsack problem (DKP) is proposed based on the concept of discount in the commercial world. The DKP contains a set of item groups where each group includes three items, whereas no more than one item in each group can be packed in the knapsack, which makes it more complex and challenging than 0-1 KP. At present, the main two algorithms for solving the DKP include exact algorithms and approximate algorithms. However, there are some topics which need to be further discussed, i.e., the improvement of the solution quality. In this paper, a novel multi-strategy monarch butterfly optimization (MMBO) algorithm for DKP is proposed. In MMBO, two effective strategies, neighborhood mutation with crowding and Gaussian perturbation, are introduced into MMBO. Experimental analyses show that the first strategy can enhance the global search ability, while the second strategy can strengthen local search ability and prevent premature convergence during the evolution process. Based on this, MBO is combined with each strategy, denoted as NCMBO and GMMBO, respectively. We compared MMBO with other six methods, including NCMBO, GMMBO, MBO, FirEGA, SecEGA and elephant herding optimization. The experimental results on three types of large-scale DKP instances show that NCMBO, GMMBO and MMBO are all suitable for solving DKP. In addition, MMBO outperforms other six methods and can achieve a good approximate solution with its approximation ratio close to 1 on almost all the DKP instances.},
	language = {en},
	number = {10},
	urldate = {2022-05-02},
	journal = {Neural Comput \& Applic},
	author = {Feng, Yanhong and Wang, Gai-Ge and Li, Wenbin and Li, Ning},
	month = nov,
	year = {2018},
	keywords = {Monarch butterfly optimization, Discounted \{0-1\} knapsack problem, Gaussian perturbation, Neighborhood mutation},
	pages = {3019--3036},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\T9N3YRT3\\Feng et al. - 2018 - Multi-strategy monarch butterfly optimization algo.pdf:application/pdf},
}

@article{joshi_interpretation_2002,
	title = {Interpretation of commercial food ingredient labels by parents of food-allergic children},
	volume = {109},
	issn = {0091-6749},
	url = {https://www.sciencedirect.com/science/article/pii/S0091674902000180},
	doi = {10.1067/mai.2002.123305},
	abstract = {Background: To avoid allergic reactions, food-allergic consumers depend on the ingredient labels of commercial products. Complex ingredient terminology (eg, casein and whey for milk) and label ambiguities (eg, natural flavor and may contain peanut ) might compromise the ability of patients/parents to determine the safety of particular products. Objective: The purpose of this investigation was to determine the accuracy of label reading among parents of food-allergic children. Methods: Parents of children on restricted diets attending our referral center were asked to review a group of 23 food labels taken from widely available commercial products. For each label, each parent/parent pair was asked to indicate whether the product was safe for the allergic child and, if it was not, which foods restricted from the child's diet were in the product. Results: There were 91 participants. Peanut was the most commonly restricted food (82 children), followed by milk, egg, soy, and wheat (60, 45, 27 and 16 children, respectively). Identification of milk and soy was the most problematic: only 4 (7\%) of 60 parents correctly identified all 14 labels that indicated milk, and only 6 (22\%) of 27 parents correctly identified soy protein in 7 products. Peanut was correctly identified in 5 products by 44 (54\%) of the 82 parents restricting peanut. Wheat (10 labels) and egg (7 labels) were correctly identified by most parents (14/16 and 42/45, respectively). Correct label identification was associated with prior instruction by a dietitian. Conclusions: With current labeling practices, most parents are unable to identify common allergenic food ingredients. These results strongly support the need for improved labeling with plain-English terminology and allergen warnings as well as the need for diligent education of patients about reading labels. (J Allergy Clin Immunol 2002;109:1019-21.)},
	language = {en},
	number = {6},
	urldate = {2022-05-02},
	journal = {Journal of Allergy and Clinical Immunology},
	author = {Joshi, Preeti and Mofidi, Shideh and Sicherer, Scott H.},
	month = jun,
	year = {2002},
	keywords = {commercial foods, Food allergy, labels},
	pages = {1019--1021},
	file = {ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\MZLMM2KD\\S0091674902000180.html:text/html},
}

@article{mackey_ease_2009,
	title = {Ease of reading of mandatory information on {Canadian} food product labels},
	volume = {33},
	issn = {1470-6431},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1470-6431.2009.00787.x},
	doi = {10.1111/j.1470-6431.2009.00787.x},
	abstract = {Food product labels present individual product information, safety, nutrition, electronic inventory, container and environmental information, in various formats, languages and images. Some information is mandatory; much is promotional. The food label is an essential tool for regulators of safe food handling, nutrition policy and fair competition. Mandatory information on food labels in Canada is required to be presented in both English and French, readily discernable, prominently displayed and legible. This study examines the ease of finding and reading of mandatory label components on selected Canadian food products. A validated typographical scoring system assessed the lists of ingredients on a purposive sample of 100 food labels representing foods in all groups in Canada's Food Guide. Seven percent of the ingredient lists were easy to read; 26\% were difficult to read and 67\% were very difficult to read. Well-educated resourceful readers in consumer focus groups examined food labels for key elements that influence ease of finding and reading information. Focus groups and typographical scoring identified: colour contrast, case, print style, print size, space between the lines, reverse print, organization, justification, type of surface, hyphenation and print reproduction as factors that affect ease of reading. Print that curves around a container, lack of paragraphing or point form organization make reading difficult; text blocks at right angles to each other make comparisons difficult; separation of the nutrition facts table from the list of ingredients makes decision making tedious. Inadequate spacing between lines of print creates problems for readers of English and exacerbates problems for readers of French. Words placed over illustrations, busy backgrounds or watermarks increase reading difficulty. Hazard statements, instructions and storage information imbedded in other information without added space or appropriate heading is difficult to find and read. Canadian consumers echo consumers in 28 European countries who find label information difficult to find and to read and want clear guidelines/regulations on the placement and the typography of mandatory food label components},
	language = {en},
	number = {4},
	urldate = {2022-05-02},
	journal = {International Journal of Consumer Studies},
	author = {Mackey, Mary Alton and Metz, Marilyn},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1470-6431.2009.00787.x},
	keywords = {Consumer, food product labels, legibility, miscue, print, readability, typography},
	pages = {369--381},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\TKITMDMS\\Mackey and Metz - 2009 - Ease of reading of mandatory information on Canadi.pdf:application/pdf;Snapshot:C\:\\Users\\croch\\Zotero\\storage\\4ZM48CV8\\j.1470-6431.2009.00787.html:text/html},
}

@article{majchrzak_progressive_nodate,
	title = {Progressive {Web} {Apps}: the {Deﬁnite} {Approach} to {Cross}-{Platform} {Development}?},
	abstract = {Although development practices for apps have matured, cross-platform development remains a prominent topic. Typically, apps should always support both Android and iOS devices. They ought to run smoothly on various hardware, and be compatible with a host of platform versions. Additionally, device categories beyond smartphone and tablets have emerged, which makes multi-platform support even trickier. Truly developing an app once and serving the multitude of possible targets remains an issue despite having crossplatform frameworks that are acknowledged by practice and research. The technology uniﬁer remains to be found, but Progressive Web Apps (PWA) might be a step towards it. In this paper, we analyse the foundations of PWAs in cross-platform development and scrutinize the status quo of current possibilities. Based on our observations, we investigate uniﬁed development, and discuss open questions. We seek to stimulate interest and narrow the immense gap that has arisen since industry started to embrace PWAs.},
	language = {en},
	author = {Majchrzak, Tim A and Biørn-Hansen, Andreas and Grønli, Tor-Morten},
	pages = {10},
	file = {Majchrzak et al. - Progressive Web Apps the Deﬁnite Approach to Cros.pdf:C\:\\Users\\croch\\Zotero\\storage\\G8ZDES8T\\Majchrzak et al. - Progressive Web Apps the Deﬁnite Approach to Cros.pdf:application/pdf},
}

@inproceedings{fortunato_progressive_2018,
	title = {Progressive web apps: {An} alternative to the native mobile {Apps}},
	shorttitle = {Progressive web apps},
	doi = {10.23919/CISTI.2018.8399228},
	abstract = {The mobile apps have been reaching a huge success on the mobile market. This opportunity attracted a lot of interested companies to have their own optimized mobile apps for all major mobile operation systems. However, these developments are expensive when developed natively for each mobile platform. New improvements done on the web technologies, allowed more features and capabilities than previously was only possible on apps that was developed natively. This started new possibilities on consolidate all developments only on web apps, that are apps that runs on web browsers. This paper intends to understand which evolutions, capabilities and limitations exists on developing a web app to run in all devices. We present the new concept of Progressive Web App, created by Google, in a way to normalize all web developments. It will be introduced the major advantages on developing the apps centralized as a Progressive Web App, comparing on developing the same solution for each different mobile platform. It will be also described the current state of web technologies and in which preferable scenarios the Progressive Web Apps are a strong alternative to the mobile native apps.},
	booktitle = {2018 13th {Iberian} {Conference} on {Information} {Systems} and {Technologies} ({CISTI})},
	author = {Fortunato, David and Bernardino, Jorge},
	month = jun,
	year = {2018},
	keywords = {Browsers, Android, Androids, Global Positioning System, Google, Humanoid robots, Internet, iOS, Mobile Native Apps, Progressive Web Apps, Smart phones, Web Apps, Windows},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\37MENS3X\\8399228.html:text/html},
}

@article{harborth_investigating_2021,
	title = {Investigating privacy concerns related to mobile augmented reality {Apps} – {A} vignette based online experiment},
	volume = {122},
	issn = {0747-5632},
	url = {https://www.sciencedirect.com/science/article/pii/S0747563221001564},
	doi = {10.1016/j.chb.2021.106833},
	abstract = {Augmented reality (AR) gained much public attention after the success of Pokémon Go in 2016, and has found application in online games, social media, interior design, and other services since then. AR is highly dependent on various different sensors gathering real time context-specific personal information about the users causing more severe and new privacy threats compared to other technologies. These threats have to be investigated as long as AR is still shapeable in order to ensure users’ privacy and foster market adoption of privacy-friendly AR systems. To provide viable recommendations regarding the design of privacy-friendly AR systems, we follow a user-centric approach and investigate the role and causes of privacy concerns within the context of mobile AR (MAR) apps. We design a vignette-based online experiment adapting ideas from the framework of contextual integrity to analyze drivers of privacy concerns related to MAR apps, such as characteristics of permissions, trust-evoking signals, and AR-related contextual factors. The results of the large-scale experiment with 1,100 participants indicate that privacy concerns are mainly determined by the sensitivity of app permissions (i.e., whether sensitive resources on the smartphone are accessed) and the number of prior app downloads. Furthermore, we devise detailed practical and theoretical implications for developers, regulatory authorities and future research.},
	language = {en},
	urldate = {2022-04-29},
	journal = {Computers in Human Behavior},
	author = {Harborth, David and Pape, Sebastian},
	month = sep,
	year = {2021},
	keywords = {Mobile augmented reality, Privacy, App permissions, App transparency, Pervasive systems, Vignette-based experiment},
	pages = {106833},
	file = {ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\25JUZRPA\\S0747563221001564.html:text/html},
}

@book{huang_human_2013,
	address = {New York, NY},
	title = {Human {Factors} in {Augmented} {Reality} {Environments}},
	isbn = {978-1-4614-4204-2 978-1-4614-4205-9},
	url = {http://link.springer.com/10.1007/978-1-4614-4205-9},
	language = {en},
	urldate = {2022-04-29},
	publisher = {Springer New York},
	editor = {Huang, Weidong and Alem, Leila and Livingston, Mark A.},
	year = {2013},
	doi = {10.1007/978-1-4614-4205-9},
	file = {Huang et al. - 2013 - Human Factors in Augmented Reality Environments.pdf:C\:\\Users\\croch\\Zotero\\storage\\FHSJANZG\\Huang et al. - 2013 - Human Factors in Augmented Reality Environments.pdf:application/pdf},
}

@article{olsson_expected_2013,
	title = {Expected user experience of mobile augmented reality services: a user study in the context of shopping centres},
	volume = {17},
	issn = {1617-4917},
	shorttitle = {Expected user experience of mobile augmented reality services},
	url = {https://doi.org/10.1007/s00779-011-0494-x},
	doi = {10.1007/s00779-011-0494-x},
	abstract = {The technical enablers for mobile augmented reality (MAR) are becoming robust enough to allow the development of MAR services that are truly valuable for consumers. Such services would provide a novel interface to the ubiquitous digital information in the physical world, hence serving in great variety of contexts and everyday human activities. To ensure the acceptance and success of future MAR services, their development should be based on knowledge about potential end users’ expectations and requirements. We conducted 16 semi-structured interview sessions with 28 participants in shopping centres, which can be considered as a fruitful context for MAR services. We aimed to elicit new knowledge about (1) the characteristics of the expected user experience and (2) central user requirements related to MAR in such a context. From a pragmatic viewpoint, the participants expected MAR services to catalyse their sense of efficiency, empower them with novel context-sensitive and proactive functionalities and raise their awareness of the information related to their surroundings with an intuitive interface. Emotionally, MAR services were expected to offer stimulating and pleasant experiences, such as playfulness, inspiration, liveliness, collectivity and surprise. The user experience categories and user requirements that were identified can serve as targets for the design of user experience of future MAR services.},
	language = {en},
	number = {2},
	urldate = {2022-04-29},
	journal = {Pers Ubiquit Comput},
	author = {Olsson, Thomas and Lagerstam, Else and Kärkkäinen, Tuula and Väänänen-Vainio-Mattila, Kaisa},
	month = feb,
	year = {2013},
	keywords = {Augmented reality, User experience, Mobile services, Ubiquitous computing, User expectations, User requirements},
	pages = {287--304},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\338HC6HQ\\Olsson et al. - 2013 - Expected user experience of mobile augmented reali.pdf:application/pdf},
}

@article{miranda_low-cost_2021,
	title = {A low-cost multi-user augmented reality application for data visualization},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-021-11141-2},
	doi = {10.1007/s11042-021-11141-2},
	abstract = {Among the existing platforms, the mobile platform provides most of the augmented reality experiences for users. Augmented reality solutions have been applied in several contexts due to technological advances in this area. However, many of these advances are still out of reach of more massive access by regular users due to access limitations or the cost of these new technologies. After conducting a literature review considering the application of data visualization in augmented reality environments, we have identified an evolution of equipment used in this context with a decrease of low-cost proposals. Hence, the works related to these two areas showed high use of technologies not yet accessible to the vast majority of users. Thus, we propose a low-cost augmented reality application that can be used on mobile devices for data visualization. We developed a hybrid proposal of an augmented reality prototype to interacting with cards through the mobile device to support the process of creating data visualization. The tangible cards have a design that helps the user in the visualization creation process, indicating each card’s role in the interaction process. The proposed application supports a multi-user environment, allowing multiple users to interact simultaneously with data visualizations in the AR environment. The visualizations are generated on a dedicated server for this function, providing a set of seven different types of visualization. To validate the developed prototype we performed two tests, the first being a stress assessment on the server that generates data visualizations to analyze the proposed application’s scalability. The second was a remote usability test with twelve participants, to evaluate the interaction and design of the cards, and the viability of this solution for augmented reality applications.},
	language = {en},
	urldate = {2022-04-29},
	journal = {Multimed Tools Appl},
	author = {Miranda, Brunelli P. and Queiroz, Vinicius F. and Araújo, Tiago D. O. and Santos, Carlos G. R. and Meiguins, Bianchi S.},
	month = jun,
	year = {2021},
	keywords = {Mobile augmented reality, Card-based interaction, Information visualization},
}

@inproceedings{pasman_implementation_2003,
	title = {Implementation of an augmented reality system on a {PDA}},
	doi = {10.1109/ISMAR.2003.1240718},
	abstract = {We present a client/server implementation for running demanding mobile AR application on a PDA device. The system incorporates various data compression methods to make it run as fast as possible on a wide range of communication networks, from GSM to WLAN.},
	booktitle = {The {Second} {IEEE} and {ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}, 2003. {Proceedings}.},
	author = {Pasman, W. and Woodward, C.},
	month = oct,
	year = {2003},
	keywords = {Augmented reality, Cameras, Hardware, Decoding, Rendering (computer graphics), Displays, GSM, Image coding, Software architecture, Wireless LAN},
	pages = {276--277},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\2QMM8WC6\\1240718.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\SGVRQR45\\Pasman and Woodward - 2003 - Implementation of an augmented reality system on a.pdf:application/pdf},
}

@inproceedings{platonov_mobile_2006,
	title = {A mobile markerless {AR} system for maintenance and repair},
	doi = {10.1109/ISMAR.2006.297800},
	abstract = {We present a solution for AR based repair guidance. This solution covers software as well as hardware related issues. In particular we developed a markerless CAD based tracking system which can deal with different illumination conditions during the tracking stage, partial occlusions and rapid motion. The system is also able to automatically recover from occasional tracking failures. On the hardware side the system is based on an off the shelf notebook, a wireless mobile setup consisting of a wide-angle video camera and an analog video transmission system. This setup has been tested with a monocular full-color video-see-through HMD and additionally with a monochrome optical-see-through HMD. Our system underwent several extensive test series under real industrial conditions and proved to be useful for different maintenance and repair scenarios.},
	booktitle = {2006 {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	author = {Platonov, Juri and Heibel, Hauke and Meier, Peter and Grollmann, Bert},
	month = oct,
	year = {2006},
	keywords = {Augmented reality, Cameras, Hardware, Tracking, Lighting, Computer vision, Computer aided manufacturing, Computer applications, Manufacturing industries, System testing},
	pages = {105--108},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\VWNHK55Y\\4079262.html:text/html},
}

@inproceedings{nazri_current_2014,
	title = {Current limitations and opportunities in mobile augmented reality applications},
	doi = {10.1109/ICCOINS.2014.6868425},
	abstract = {Mobile AR has evolved from the bulkiness of head-mounted device and backpack device to smart device (smartphone, tablet etc.). To date, the current implementation has made what AR is today. However, the advancement of AR technology has met with limitation and challenges on its own, which resulted in not able to reach mass-market. This paper in turn presents current limitations and challenges that need to overcome. We have done a review based on past research papers on limitation in technical (hardware, algorithms and interaction technique) and non-technical (social acceptance, privacy and usefulness) aspects of developing and implementing mobile augmented reality applications. We also presented some future opportunities in mobile AR applications.},
	booktitle = {2014 {International} {Conference} on {Computer} and {Information} {Sciences} ({ICCOINS})},
	author = {Nazri, Nur Intan Adhani Muhamad and Rambli, Dayang Rohaya Awang},
	month = jun,
	year = {2014},
	keywords = {Augmented reality, Mobile augmented reality, Mobile handsets, Mobile communication, Hardware, Privacy, Industries, Google, mobile interaction, multimodal interaction},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\CFGLA9TX\\6868425.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\DRMIF3UY\\Nazri and Rambli - 2014 - Current limitations and opportunities in mobile au.pdf:application/pdf},
}

@inproceedings{oufqir_arkit_2020,
	title = {{ARKit} and {ARCore} in serve to augmented reality},
	doi = {10.1109/ISCV49265.2020.9204243},
	abstract = {Many libraries are available in the development world to create augmented reality applications, their functionality differs depending on the technology used to detect and track an object, points or features in a scene. In this article, we will discover ARKit, ARCore two open source libraries that display a virtual object in the real world. Their goal is to merge digital content and information with the real world. They can interact with the components of the device (camera and screen) to detect and track characteristics of the scene in order to insert virtual content. This study implements and concretizes the different functionalities available in augmented reality to enrich the real world with additional information.},
	booktitle = {2020 {International} {Conference} on {Intelligent} {Systems} and {Computer} {Vision} ({ISCV})},
	author = {Oufqir, Zainab and El Abderrahmani, Abdellatif and Satori, Khalid},
	month = jun,
	year = {2020},
	keywords = {Augmented reality, augmented reality, Cameras, Three-dimensional displays, Tracking, Feature extraction, Games, arcore, arkit, Faces, real world, virtual 3D object},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\UBE9GAKJ\\9204243.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\2KWWQMRZ\\Oufqir et al. - 2020 - ARKit and ARCore in serve to augmented reality.pdf:application/pdf},
}

@article{chatzopoulos_mobile_2017,
	title = {Mobile {Augmented} {Reality} {Survey}: {From} {Where} {We} {Are} to {Where} {We} {Go}},
	volume = {5},
	issn = {2169-3536},
	shorttitle = {Mobile {Augmented} {Reality} {Survey}},
	doi = {10.1109/ACCESS.2017.2698164},
	abstract = {The boom in the capabilities and features of mobile devices, like smartphones, tablets, and wearables, combined with the ubiquitous and affordable Internet access and the advances in the areas of cooperative networking, computer vision, and mobile cloud computing transformed mobile augmented reality (MAR) from science fiction to a reality. Although mobile devices are more constrained computationalwise from traditional computers, they have a multitude of sensors that can be used to the development of more sophisticated MAR applications and can be assisted from remote servers for the execution of their intensive parts. In this paper, after introducing the reader to the basics of MAR, we present a categorization of the application fields together with some representative examples. Next, we introduce the reader to the user interface and experience in MAR applications and continue with the core system components of the MAR systems. After that, we discuss advances in tracking and registration, since their functionality is crucial to any MAR application and the network connectivity of the devices that run MAR applications together with its importance to the performance of the application. We continue with the importance of data management in MAR systems and the systems performance and sustainability, and before we conclude this survey, we present existing challenging problems.},
	journal = {IEEE Access},
	author = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Hui, Pan},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {Augmented reality, Mobile augmented reality, Mobile communication, Mobile computing, Cloud computing, Sensors, Smart phones, human computer interaction, mobile computing},
	pages = {6917--6950},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\Y3XAUIY2\\7912316.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\93AEJSVC\\Chatzopoulos et al. - 2017 - Mobile Augmented Reality Survey From Where We Are.pdf:application/pdf},
}

@inproceedings{zhang_networking_2017,
	address = {New York, NY, USA},
	series = {{VR}/{AR} {Network} '17},
	title = {On the {Networking} {Challenges} of {Mobile} {Augmented} {Reality}},
	isbn = {978-1-4503-5055-6},
	url = {https://doi.org/10.1145/3097895.3097900},
	doi = {10.1145/3097895.3097900},
	abstract = {In this paper, we conduct a reality check for Augmented Reality (AR) on mobile devices. We dissect and measure the cloud-offloading feature for computation-intensive visual tasks of two popular commercial AR systems. Our key finding is that their cloud-based recognition is still not mature and not optimized for latency, data usage and energy consumption. In order to identify the opportunities for further improving the Quality of Experience (QoE) for mobile AR, we break down the end-to-end latency of the pipeline for typical cloud-based mobile AR and pinpoint the dominating components in the critical path.},
	urldate = {2022-04-28},
	booktitle = {Proceedings of the {Workshop} on {Virtual} {Reality} and {Augmented} {Reality} {Network}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Wenxiao and Han, Bo and Hui, Pan},
	month = aug,
	year = {2017},
	keywords = {Augmented reality, cloud offloading, end-to-end latency, networking challenges, reality check},
	pages = {24--29},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\AWGTGIWZ\\Zhang et al. - 2017 - On the Networking Challenges of Mobile Augmented R.pdf:application/pdf},
}

@article{poushneh_augmented_2018,
	title = {Augmented reality in retail: {A} trade-off between user's control of access to personal information and augmentation quality},
	volume = {41},
	issn = {0969-6989},
	shorttitle = {Augmented reality in retail},
	url = {https://www.sciencedirect.com/science/article/pii/S0969698917305969},
	doi = {10.1016/j.jretconser.2017.12.010},
	abstract = {This study conducted a qualitative experimental study to develop a scale, augmentation quality that measures the output quality of augmented reality. Augmentation quality is a new aspect of user experience being captured through interaction with augmented reality. Since controlling access to their personal information is a significant concern of users, this study also conducted a quantitative experimental study and applied equity theory to examine how augmentation quality and users’ control of access to their personal information impacts user satisfaction. This study was conducted in three different contexts: online shopping, entertainment services, and basic service maintenance. ANOVA was applied to examine the significant differences in user satisfaction, user's control of access to personal information, and augmentation quality across the three contexts. Results indicated that individuals pay attention to both the privacy of their personal information as well as augmentation quality. The results also indicated that the ability to control access to personal information significantly affects user satisfaction. The results of this study carry important managerial implications for augmented reality developers and retailers.},
	language = {en},
	urldate = {2022-04-29},
	journal = {Journal of Retailing and Consumer Services},
	author = {Poushneh, Atieh},
	month = mar,
	year = {2018},
	keywords = {Augmented reality, Augmentation quality, User satisfaction, User's control of access to personal information},
	pages = {169--176},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\PQFP8FYQ\\Poushneh - 2018 - Augmented reality in retail A trade-off between u.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\V9E5TNWM\\S0969698917305969.html:text/html},
}

@article{spreer_augmented_2014,
	title = {Augmented {Reality} in {Retail}: {Assessing} the {Acceptance} and {Potential} for {Multimedia} {Product} {Presentation} at the {PoS}},
	volume = {1},
	shorttitle = {Augmented {Reality} in {Retail}},
	doi = {10.15764/MR.2014.01002},
	abstract = {Augmented Reality (AR) is currently one of the most discussed marketing topics in retailing and has already been adopted by companies such as Adidas or Lego. However, apart from conceptual findings, little is known about the factors which drive the users’ acceptance and its potential for the presentation of product-related information. This article examines the use of an AR application with an experimental field study in cooperation with one of the largest German booksellers and a leading AR development company. The results reveal that AR has the potential to improve the assessment of information at the PoS. Furthermore, we show that AR applications need to offer both a clear customer benefit and enjoyment-related elements to ensure the users' acceptance.},
	journal = {Transactions on Marketing Research},
	author = {Spreer, Philipp and Kallweit, Katrin},
	month = feb,
	year = {2014},
	pages = {20--25},
}

@article{berman_strategies_2021,
	title = {Strategies for the successful implementation of augmented reality},
	volume = {64},
	issn = {0007-6813},
	url = {https://www.sciencedirect.com/science/article/pii/S000768132100029X},
	doi = {10.1016/j.bushor.2021.02.027},
	abstract = {The potential benefits of augmented reality (AR) to consumers include high levels of interactivity, exposure to an extensive virtual inventory tailored to their needs, high-quality customer support, and better integration between web- and store-based shopping experiences. The anticipated benefits of a successful AR strategy to a brand or retailer include higher inventory turnover, increased average sales, reduced sales costs, lower customer returns, higher levels of related-item selling, and better customer support outcomes. Despite these revenue- and loyalty-enhancing benefits, few companies use AR, develop a highly integrated AR plan, or incorporate AR into their marketing programs. This article focuses on the successful planning and implementation of AR through a six-step process: (1) Determine how AR can help achieve marketing objectives; (2) choose appropriate products, channels, and target markets for AR; (3) select among AR application types; (4) design AR apps; (5) evaluate alternative AR organizational formats; and (6) measure the success of AR programs.},
	language = {en},
	number = {5},
	urldate = {2022-04-29},
	journal = {Business Horizons},
	author = {Berman, Barry and Pollack, Debra},
	month = sep,
	year = {2021},
	keywords = {Augmented reality, Application\_Design, Virtual mirrors, Virtual presentation, Virtual reality, Virtual try-ons},
	pages = {621--630},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\SUWA4AJE\\Berman and Pollack - 2021 - Strategies for the successful implementation of au.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\STXGE3T2\\S000768132100029X.html:text/html},
}

@inproceedings{jain_overlay_2015,
	address = {Florence Italy},
	title = {{OverLay}: {Practical} {Mobile} {Augmented} {Reality}},
	isbn = {978-1-4503-3494-5},
	shorttitle = {{OverLay}},
	url = {https://dl.acm.org/doi/10.1145/2742647.2742666},
	doi = {10.1145/2742647.2742666},
	abstract = {The idea of augmented reality – the ability to look at a physical object through a camera and view annotations about the object – is certainly not new. Yet, this apparently feasible vision has not yet materialized into a precise, fast, and comprehensively usable system. This paper asks: What does it take to enable augmented reality (AR) on smartphones today? To build a ready-to-use mobile AR system, we adopt a top-down approach cutting across smartphone sensing, computer vision, cloud ofﬂoading, and linear optimization. Our core contribution is in a novel location-free geometric representation of the environment – from smartphone sensors – and using this geometry to prune down the visual search space. Metrics of success include both accuracy and latency of object identiﬁcation, coupled with the ease of use and scalability in uncontrolled environments. Our converged system, OverLay, is currently deployed in the engineering building and open for use to regular public; ongoing work is focussed on campuswide deployment to serve as a “historical tour guide” of UIUC. Performance results and user responses thus far have been promising, to say the least.},
	language = {en},
	urldate = {2022-04-29},
	booktitle = {Proceedings of the 13th {Annual} {International} {Conference} on {Mobile} {Systems}, {Applications}, and {Services}},
	publisher = {ACM},
	author = {Jain, Puneet and Manweiler, Justin and Roy Choudhury, Romit},
	month = may,
	year = {2015},
	pages = {331--344},
	file = {Jain et al. - 2015 - OverLay Practical Mobile Augmented Reality.pdf:C\:\\Users\\croch\\Zotero\\storage\\7F5W6L4T\\Jain et al. - 2015 - OverLay Practical Mobile Augmented Reality.pdf:application/pdf},
}

@article{kourouthanassis_demystifying_2015,
	title = {Demystifying the design of mobile augmented reality applications},
	volume = {74},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-013-1710-7},
	doi = {10.1007/s11042-013-1710-7},
	abstract = {This research proposes a set of interaction design principles for the development of mobile augmented reality (MAR) applications. The design recommendations adopt a user-centered perspective and, thus, they focus on the necessary actions to ensure high-quality MAR user experiences. To formulate our propositions we relied on theoretical grounding and an evaluation of eight MAR applications that provide published records of their design properties. The design principles have then been applied to guide the development of a MAR travel application. We performed a field study with 33 tourists in order to elicit whether our design choices effectively lead to enhanced satisfaction and overall user experience. Results suggest that the proposed principles contribute to ensuring high usability and performance of the MAR application as well as evoking positive feelings during user and system interactions. Our prescriptions may be employed either as a guide during the initial stages of the design process (ex-ante usage) or as a benchmark to assess the performance (ex-post usage) of MAR applications.},
	language = {en},
	number = {3},
	urldate = {2022-04-29},
	journal = {Multimed Tools Appl},
	author = {Kourouthanassis, Panos E. and Boletsis, Costas and Lekakos, George},
	month = feb,
	year = {2015},
	keywords = {User experience, Mobile augmented reality, Application\_Design, Design principles, Field study},
	pages = {1045--1066},
	file = {Full Text PDF:C\:\\Users\\croch\\Zotero\\storage\\I5CITT6W\\Kourouthanassis et al. - 2015 - Demystifying the design of mobile augmented realit.pdf:application/pdf},
}

@incollection{hart_development_1988,
	series = {Human {Mental} {Workload}},
	title = {Development of {NASA}-{TLX} ({Task} {Load} {Index}): {Results} of {Empirical} and {Theoretical} {Research}},
	volume = {52},
	shorttitle = {Development of {NASA}-{TLX} ({Task} {Load} {Index})},
	url = {https://www.sciencedirect.com/science/article/pii/S0166411508623869},
	abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
	urldate = {2024-07-02},
	booktitle = {Advances in {Psychology}},
	publisher = {North-Holland},
	author = {Hart, Sandra G. and Staveland, Lowell E.},
	editor = {Hancock, Peter A. and Meshkati, Najmedin},
	month = jan,
	year = {1988},
	doi = {10.1016/S0166-4115(08)62386-9},
	pages = {139--183},
	file = {ScienceDirect Snapshot:C\:\\Users\\croch\\Zotero\\storage\\YCAM9U3A\\S0166411508623869.html:text/html},
}

@misc{nielsen_response_1993,
	title = {Response {Times}: {The} 3 {Important} {Limits}},
	shorttitle = {Response {Time} {Limits}},
	url = {https://www.nngroup.com/articles/response-times-3-important-limits/},
	abstract = {How users react to delays in a user interface, whether website or application. The 3 main response time limits are determined by human perceptual abilities.},
	language = {en},
	urldate = {2024-07-02},
	journal = {Nielsen Norman Group},
	author = {Nielsen, Jakob},
	month = jan,
	year = {1993},
	file = {Snapshot:C\:\\Users\\croch\\Zotero\\storage\\WHWSCHBX\\response-times-3-important-limits.html:text/html},
}

@article{galy_measuring_2018,
	title = {Measuring mental workload with the {NASA}-{TLX} needs to examine each dimension rather than relying on the global score: an example with driving},
	volume = {61},
	issn = {0014-0139},
	shorttitle = {Measuring mental workload with the {NASA}-{TLX} needs to examine each dimension rather than relying on the global score},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00140139.2017.1369583},
	doi = {10.1080/00140139.2017.1369583},
	number = {4},
	urldate = {2024-07-21},
	journal = {Ergonomics},
	author = {Galy, Edith and Paxion, Julie and Berthelon, Catherine},
	month = apr,
	year = {2018},
	note = {Publisher: Taylor \& Francis},
	keywords = {alertness, driving, experience, load dimensions, Mental workload},
	pages = {517--527},
	file = {Submitted Version:C\:\\Users\\croch\\Zotero\\storage\\RHNM988P\\Galy et al. - 2018 - Measuring mental workload with the NASA-TLX needs .pdf:application/pdf},
}

@misc{noauthor_determining_2009,
	title = {Determining {What} {Individual} {SUS} {Scores} {Mean}: {Adding} an {Adjective} {Rating} {Scale} - {JUX}},
	shorttitle = {Determining {What} {Individual} {SUS} {Scores} {Mean}},
	url = {https://uxpajournal.org/determining-what-individual-sus-scores-mean-adding-an-adjective-rating-scale/},
	abstract = {Abstract The System Usability Scale (SUS) is an inexpensive, yet effective tool for assessing the usability of a product, including Web sites, cell phones, interactive voice response systems, TV applications, and more. It provides an easy-to-understand score from 0 (negative) to 100 (positive). While a 100-point scale is intuitive in many respects and allows for},
	language = {en},
	urldate = {2024-07-21},
	journal = {JUX - The Journal of User Experience},
	month = may,
	year = {2009},
	file = {Snapshot:C\:\\Users\\croch\\Zotero\\storage\\HM2UWH74\\determining-what-individual-sus-scores-mean-adding-an-adjective-rating-scale.html:text/html},
}

@inproceedings{roche_mobile_2023,
	title = {Mobile {Augmented} {Reality} {Shopping} {System}},
	url = {https://ieeexplore.ieee.org/document/10115069},
	doi = {10.1109/SoutheastCon51012.2023.10115069},
	abstract = {This document serves as an extended abstract to detail the architecture for an augmented reality shopping application under current development for a thesis. The system consists of a progressive web app client that presents the augmented view to the user and performs object tracking, and a cloud server that performs object detection, localization, and the necessary product information retrieval and analysis.},
	urldate = {2024-08-10},
	booktitle = {{SoutheastCon} 2023},
	author = {Roche, Colter and Hamam, Abdelwehab},
	month = apr,
	year = {2023},
	note = {ISSN: 1558-058X},
	keywords = {augmented reality, Cloud computing, Computer architecture, Information retrieval, Location awareness, mobile augmented reality, mobile computing, Object detection, object recognition, Object tracking, progressive web app, Servers, webAR},
	pages = {704--705},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\croch\\Zotero\\storage\\U8N4MECB\\10115069.html:text/html},
}

@inproceedings{roche_augmented_2023,
	title = {Augmented {Reality} {Shopping} {System} and {Experience}: {Overview} of the {Literature}},
	shorttitle = {Augmented {Reality} {Shopping} {System} and {Experience}},
	url = {https://ieeexplore.ieee.org/document/10115104},
	doi = {10.1109/SoutheastCon51012.2023.10115104},
	abstract = {This paper reviews literature related to the architecture for a proposed augmented reality shopping application under current development. The system consists of a progressive web app client that renders augmentations for the user and performs tracking, and a cloud server that performs object detection, localization, and product information retrieval and analysis. This review provides an overview of past cloud-based augmented reality applications and identifies design factors for the proposed system.},
	urldate = {2024-08-10},
	booktitle = {{SoutheastCon} 2023},
	author = {Roche, Colter and Hamam, Abdelwehab},
	month = apr,
	year = {2023},
	note = {ISSN: 1558-058X},
	keywords = {augmented reality, Computer architecture, Image recognition, Information retrieval, Location awareness, mobile augmented reality, mobile computing, Object detection, object recognition, Performance evaluation, progressive web app, Shape, webAR},
	pages = {471--476},
}
